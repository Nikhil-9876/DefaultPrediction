{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-mKM6tJrZD-",
        "outputId": "8fa75cc0-8eb4-4701-f9c1-3122263a8950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded loan dataset: (255347, 18)\n",
            "[INFO] Loaded telco dataset: (7043, 21)\n",
            "[TRAIN] ✅ Enhanced training set: credit_risk_output/training_data_aligned.csv shape=(12000, 43)\n",
            "[TRAIN] Risk distribution: {'Medium Risk': 5297, 'High Risk': 3209, 'Low Risk': 2103, 'Very High Risk': 1391}\n",
            "[TRAIN] PD range: 0.010 - 0.920\n",
            "[TRAIN] Application amount range: ₹25,000 - ₹8,000,000\n",
            "\n",
            "[INFO] Dataset Integration Summary:\n",
            "  - Loan dataset: ✅ Loaded\n",
            "  - Telco dataset: ✅ Loaded\n",
            "\n",
            "\n",
            "\n",
            "  - Tenure sampling: μ=32.4, σ=24.6\n",
            "  - Charges sampling: μ=64.8, σ=30.1\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Train data generator (preserves exact columns; writes training_data_aligned.csv)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "np.random.seed(111)\n",
        "\n",
        "OUT_DIR = \"credit_risk_output\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "#  NEW: Load external reference datasets\n",
        "# -------------------------------\n",
        "LOAN_DATA_PATH = \"Loan_default (1).csv\"\n",
        "TELCO_DATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "# Safe loading with error handling\n",
        "try:\n",
        "    loan_df = pd.read_csv(LOAN_DATA_PATH)\n",
        "    print(f\"[INFO] Loaded loan dataset: {loan_df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[WARNING] {LOAN_DATA_PATH} not found. Using fallback distributions.\")\n",
        "    loan_df = None\n",
        "\n",
        "try:\n",
        "    telco_df = pd.read_csv(TELCO_DATA_PATH)\n",
        "    print(f\"[INFO] Loaded telco dataset: {telco_df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[WARNING] {TELCO_DATA_PATH} not found. Using fallback distributions.\")\n",
        "    telco_df = None\n",
        "\n",
        "# Pre-calculate distributions from loan dataset\n",
        "if loan_df is not None:\n",
        "    loan_age_stats = loan_df[\"age\"].dropna().describe() if \"age\" in loan_df.columns else None\n",
        "    loan_income_stats = loan_df[\"income\"].dropna().describe() if \"income\" in loan_df.columns else None\n",
        "    loan_amount_stats = loan_df[\"loan_amount\"].dropna().describe() if \"loan_amount\" in loan_df.columns else None\n",
        "else:\n",
        "    loan_age_stats = loan_income_stats = loan_amount_stats = None\n",
        "\n",
        "# Pre-calculate distributions from telco dataset\n",
        "if telco_df is not None:\n",
        "    telco_tenure_stats = telco_df[\"tenure\"].dropna().describe() if \"tenure\" in telco_df.columns else None\n",
        "    telco_charges_stats = telco_df[\"MonthlyCharges\"].dropna().describe() if \"MonthlyCharges\" in telco_df.columns else None\n",
        "else:\n",
        "    telco_tenure_stats = telco_charges_stats = None\n",
        "\n",
        "# -------------------------------\n",
        "# Core model features (updated to include loan application amount)\n",
        "# -------------------------------\n",
        "MODEL_FEATURES = [\n",
        "    \"age\", \"monthly_income_inr\", \"monthly_expenses_inr\", \"monthly_savings_inr\",\n",
        "    \"outstanding_loan_amount_inr\", \"loan_amount_applied_inr\", \"years_current_employment\", \"banking_relationship_years\",\n",
        "    \"timeliness_score\", \"repayment_ability_score\", \"financial_health_score\",\n",
        "    \"payment_reliability_score\", \"stability_index\"\n",
        "]\n",
        "\n",
        "TARGET_REG = \"probability_of_default\"\n",
        "TARGET_CLS = \"risk_category\"\n",
        "\n",
        "# Updated column list with new loan application amount\n",
        "ALL_COLUMNS = [\n",
        "    \"applicant_id\", \"application_date\", \"age\", \"gender\", \"education_level\",\n",
        "    \"employment_type\", \"marital_status\", \"family_size\", \"number_of_dependents\",\n",
        "    \"location_type\", \"monthly_income_inr\", \"spouse_income_inr\", \"monthly_expenses_inr\",\n",
        "    \"monthly_savings_inr\", \"monthly_utility_bills_inr\", \"property_value_inr\",\n",
        "    \"vehicle_value_inr\", \"total_investments_inr\", \"outstanding_loan_amount_inr\",\n",
        "    \"loan_amount_applied_inr\", \"years_current_employment\", \"banking_relationship_years\",\n",
        "    \"monthly_business_revenue_inr\", \"daily_mobile_hours\", \"monthly_digital_transactions\",\n",
        "    \"avg_transaction_amount_inr\", \"social_media_accounts_count\", \"mobile_app_usage_intensity_score\",\n",
        "    \"digital_payment_adoption_score\", \"utility_payment_regularity_score\",\n",
        "    \"location_stability_score\", \"mobile_banking_usage_score\", \"payment_reliability_score\",\n",
        "    \"financial_health_score\", \"stability_index\", \"timeliness_score\",\n",
        "    \"repayment_ability_score\", \"probability_of_default\", \"data_completeness_pct\",\n",
        "    \"consent_status\", \"explainability_support_flag\", \"city\", \"risk_category\"\n",
        "]\n",
        "\n",
        "GUJARAT_CITIES = [\n",
        "    \"Ahmedabad\", \"Surat\", \"Vadodara\", \"Rajkot\", \"Bhavnagar\", \"Jamnagar\", \"Junagadh\",\n",
        "    \"Gandhinagar\", \"Nadiad\", \"Morbi\", \"Anand\", \"Mehsana\", \"Navsari\", \"Bharuch\",\n",
        "    \"Vapi\", \"Valsad\", \"Patan\", \"Godhra\", \"Porbandar\", \"Palanpur\", \"Veraval\", \"Surendranagar\"\n",
        "]\n",
        "EDUCATION_LEVELS = [\"High School\", \"Diploma\", \"Graduate\", \"Post Graduate\", \"Professional\"]\n",
        "EMPLOYMENT_TYPES = [\"Salaried\", \"Self Employed\", \"Business Owner\", \"Professional\"]\n",
        "LOCATION_TYPES = [\"Metro\", \"Tier1\", \"Tier2\"]\n",
        "\n",
        "# NEW: City to location type mapping as specified\n",
        "CITY_TO_LOCATION_TYPE = {\n",
        "    \"Ahmedabad\": \"Metro\",\n",
        "    \"Surat\": \"Metro\",\n",
        "    \"Vadodara\": \"Metro\",\n",
        "    \"Rajkot\": \"Tier1\",\n",
        "    \"Bhavnagar\": \"Tier1\",\n",
        "    \"Jamnagar\": \"Tier1\",\n",
        "    \"Junagadh\": \"Tier2\",\n",
        "    \"Gandhinagar\": \"Metro\",\n",
        "    \"Nadiad\": \"Tier2\",\n",
        "    \"Morbi\": \"Tier2\",\n",
        "    \"Anand\": \"Tier2\",\n",
        "    \"Mehsana\": \"Tier2\",\n",
        "    \"Navsari\": \"Tier2\",\n",
        "    \"Bharuch\": \"Tier2\",\n",
        "    \"Vapi\": \"Tier2\",\n",
        "    \"Valsad\": \"Tier2\",\n",
        "    \"Patan\": \"Tier2\",\n",
        "    \"Godhra\": \"Tier2\",\n",
        "    \"Porbandar\": \"Tier2\",\n",
        "    \"Palanpur\": \"Tier2\",\n",
        "    \"Veraval\": \"Tier2\",\n",
        "    \"Surendranagar\": \"Tier1\"\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# NEW: Sampling functions from datasets\n",
        "# -------------------------------\n",
        "def _sample_age():\n",
        "    \"\"\"Sample age from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_age_stats is not None:\n",
        "        sampled_age = int(np.random.normal(loan_age_stats[\"mean\"], loan_age_stats[\"std\"]))\n",
        "        return max(18, min(75, sampled_age))  # Clip to reasonable range\n",
        "    else:\n",
        "        # Fallback to original distribution\n",
        "        return int(np.random.normal(36, 12))\n",
        "\n",
        "def _sample_income():\n",
        "    \"\"\"Sample income from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_income_stats is not None:\n",
        "        sampled_income = int(np.random.normal(loan_income_stats[\"mean\"], loan_income_stats[\"std\"]))\n",
        "        return max(15000, min(500000, sampled_income))  # Clip to reasonable range\n",
        "    else:\n",
        "        # Fallback to original distribution\n",
        "        return int(np.random.normal(55000, 25000))\n",
        "\n",
        "def _sample_loan_amount():\n",
        "    \"\"\"Sample loan amount from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_amount_stats is not None:\n",
        "        sampled_amount = int(np.random.normal(loan_amount_stats[\"mean\"], loan_amount_stats[\"std\"]))\n",
        "        return max(15000, min(6000000, sampled_amount))  # Clip to reasonable range\n",
        "    else:\n",
        "        # Fallback to original distribution\n",
        "        return int(np.random.normal(250000, 80000))\n",
        "\n",
        "def _sample_tenure():\n",
        "    \"\"\"Sample tenure/relationship years from telco dataset or fallback\"\"\"\n",
        "    if telco_tenure_stats is not None:\n",
        "        sampled_tenure = np.random.normal(telco_tenure_stats[\"mean\"], telco_tenure_stats[\"std\"])\n",
        "        return max(0.5, min(35.0, sampled_tenure))  # Clip to reasonable range\n",
        "    else:\n",
        "        # Fallback to original distribution\n",
        "        return np.random.uniform(0.5, 15.0)\n",
        "\n",
        "def _sample_digital_transactions():\n",
        "    \"\"\"Sample digital transaction count based on telco usage patterns\"\"\"\n",
        "    if telco_charges_stats is not None:\n",
        "        # Use monthly charges as proxy for digital activity\n",
        "        base_transactions = int(telco_charges_stats[\"mean\"] / 2)  # Rough conversion\n",
        "        noise = np.random.normal(0, telco_charges_stats[\"std\"] / 4)\n",
        "        return max(5, int(base_transactions + noise))\n",
        "    else:\n",
        "        # Fallback to original distribution\n",
        "        base = int(np.random.normal(60, 20))\n",
        "        return max(5, base)\n",
        "\n",
        "def _sample_monthly_charges():\n",
        "    \"\"\"Sample monthly charges/utility bills from telco dataset\"\"\"\n",
        "    if telco_charges_stats is not None:\n",
        "        charges = np.random.normal(telco_charges_stats[\"mean\"], telco_charges_stats[\"std\"])\n",
        "        return max(500, int(charges * 60))  # Convert USD to INR approximately\n",
        "    else:\n",
        "        return int(np.random.normal(2500, 800))\n",
        "\n",
        "# -------------------------------\n",
        "# NEW: Function to generate realistic loan application amount\n",
        "# -------------------------------\n",
        "def _generate_loan_application_amount(income, age, segment, property_value, employment_type):\n",
        "    \"\"\"\n",
        "    Generate realistic loan application amount based on customer profile\n",
        "    \"\"\"\n",
        "    # Base application amount from dataset sampling\n",
        "    base_amount = _sample_loan_amount()\n",
        "\n",
        "    # Income-based adjustment (higher income = higher applications)\n",
        "    income_multiplier = min(3.0, max(0.3, income / 50000))\n",
        "\n",
        "    # Age-based loan purpose patterns\n",
        "    if age < 30:\n",
        "        # Young people: personal loans, vehicle loans, small home loans\n",
        "        purpose_multiplier = np.random.choice([0.6, 1.2, 2.0], p=[0.5, 0.3, 0.2])\n",
        "    elif age < 45:\n",
        "        # Prime age: home loans, business loans, higher amounts\n",
        "        purpose_multiplier = np.random.choice([1.0, 2.5, 4.0], p=[0.3, 0.4, 0.3])\n",
        "    else:\n",
        "        # Mature: consolidation, business expansion, moderate amounts\n",
        "        purpose_multiplier = np.random.choice([0.8, 1.8, 3.0], p=[0.4, 0.4, 0.2])\n",
        "\n",
        "    # Property ownership influence\n",
        "    if property_value > 0:\n",
        "        # Existing property owners tend to apply for larger amounts\n",
        "        property_multiplier = np.random.uniform(1.2, 2.0)\n",
        "    else:\n",
        "        property_multiplier = np.random.uniform(0.7, 1.3)\n",
        "\n",
        "    # Employment type influence\n",
        "    employment_multipliers = {\n",
        "        \"Salaried\": np.random.uniform(0.8, 1.4),\n",
        "        \"Professional\": np.random.uniform(1.0, 1.8),\n",
        "        \"Business Owner\": np.random.uniform(1.2, 2.5),\n",
        "        \"Self Employed\": np.random.uniform(0.6, 1.6)\n",
        "    }\n",
        "    emp_multiplier = employment_multipliers.get(employment_type, 1.0)\n",
        "\n",
        "    # Segment-based adjustments\n",
        "    segment_adjustments = {\n",
        "        \"excellent\": np.random.uniform(1.5, 3.0),  # Apply for larger amounts\n",
        "        \"good\": np.random.uniform(1.0, 2.0),\n",
        "        \"fair\": np.random.uniform(0.7, 1.5),\n",
        "        \"poor\": np.random.uniform(0.4, 1.0),\n",
        "        \"bad\": np.random.uniform(0.3, 0.8)  # Smaller applications due to desperation\n",
        "    }\n",
        "    segment_multiplier = segment_adjustments.get(segment, 1.0)\n",
        "\n",
        "    # Calculate final application amount\n",
        "    application_amount = int(base_amount * income_multiplier * purpose_multiplier *\n",
        "                           property_multiplier * emp_multiplier * segment_multiplier)\n",
        "\n",
        "    # Realistic bounds (minimum 25k, maximum 8x annual income)\n",
        "    min_amount = 25000\n",
        "    max_amount = min(8000000, int(income * 12 * 8))  # Max 8x annual income\n",
        "\n",
        "    return max(min_amount, min(max_amount, application_amount))\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions (unchanged)\n",
        "# -------------------------------\n",
        "def _clip(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def _sigmoid(x):\n",
        "    import numpy as _np\n",
        "    return 1.0 / (1.0 + _np.exp(-_np.clip(x, -500, 500)))\n",
        "\n",
        "def _risk_category_from_p(p):\n",
        "    if p <= 0.18: return \"Low Risk\"\n",
        "    elif p <= 0.42: return \"Medium Risk\"\n",
        "    elif p <= 0.68: return \"High Risk\"\n",
        "    else: return \"Very High Risk\"\n",
        "\n",
        "def _generate_applicant_id():\n",
        "    prefix = np.random.choice([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"])\n",
        "    number = np.random.randint(1000, 9999)\n",
        "    return f\"{prefix}{number:04d}\"\n",
        "\n",
        "def _generate_application_date():\n",
        "    start_date = datetime(2024, 6, 1)\n",
        "    end_date = datetime(2025, 7, 31)\n",
        "    days_diff = (end_date - start_date).days\n",
        "    random_days = np.random.randint(0, max(1, days_diff))\n",
        "    return (start_date + timedelta(days=int(random_days))).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def calculate_data_driven_scores(row):\n",
        "    \"\"\"\n",
        "    Calculate scores based on actual financial data including loan application amount.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Extract key financial metrics\n",
        "    income = max(1.0, float(row[\"monthly_income_inr\"]))\n",
        "    expenses = float(row[\"monthly_expenses_inr\"])\n",
        "    savings = float(row[\"monthly_savings_inr\"])\n",
        "    loan_amount = float(row[\"outstanding_loan_amount_inr\"])\n",
        "    application_amount = float(row[\"loan_amount_applied_inr\"])  # NEW\n",
        "    age = int(row[\"age\"])\n",
        "    emp_years = float(row[\"years_current_employment\"])\n",
        "    bank_years = float(row[\"banking_relationship_years\"])\n",
        "    property_value = float(row[\"property_value_inr\"])\n",
        "    investments = float(row[\"total_investments_inr\"])\n",
        "\n",
        "    # Calculate ratios including new application-based metrics\n",
        "    dti_ratio = loan_amount / (12.0 * income) if income > 0 else 0\n",
        "    application_to_income_ratio = application_amount / (12.0 * income) if income > 0 else 0\n",
        "    loan_utilization_ratio = loan_amount / max(1.0, application_amount)  # How much of applied amount is outstanding\n",
        "    expense_ratio = expenses / income if income > 0 else 1\n",
        "    savings_ratio = savings / income if income > 0 else 0\n",
        "\n",
        "    def _clip_local(value, min_val, max_val):\n",
        "        return max(min_val, min(max_val, value))\n",
        "\n",
        "    # 1. TIMELINESS SCORE (5-95) - Enhanced with application amount consideration\n",
        "    timeliness_base = (\n",
        "        min(emp_years * 8, 40) +\n",
        "        min(bank_years * 6, 30) +\n",
        "        min((age - 18) * 0.8, 20) +\n",
        "        5\n",
        "    )\n",
        "    # Enhanced penalties including application behavior\n",
        "    timeliness_penalty = (dti_ratio * 15 +\n",
        "                         max(0, expense_ratio - 0.7) * 20 +\n",
        "                         max(0, application_to_income_ratio - 1.5) * 10)  # Penalty for over-application\n",
        "    timeliness_score = _clip_local(int(timeliness_base - timeliness_penalty + np.random.randint(-8, 9)), 5, 95)\n",
        "\n",
        "    # 2. REPAYMENT ABILITY SCORE (5-90) - Enhanced with application amount factors\n",
        "    repayment_base = (\n",
        "        min(np.log(income/25000) * 15, 30) +\n",
        "        max(0, savings_ratio * 40) +\n",
        "        min(emp_years * 2, 20)\n",
        "    )\n",
        "    # Enhanced penalties considering application vs outstanding ratio\n",
        "    repayment_penalty = (dti_ratio * 25 +\n",
        "                        max(0, expense_ratio - 0.8) * 15 +\n",
        "                        max(0, application_to_income_ratio - 2.0) * 12 +  # Over-application penalty\n",
        "                        max(0, loan_utilization_ratio - 0.9) * 8)  # High utilization penalty\n",
        "    repayment_score = _clip_local(int(repayment_base - repayment_penalty + np.random.randint(-6, 7)), 5, 90)\n",
        "\n",
        "    # 3. FINANCIAL HEALTH SCORE (10-95) - Enhanced with application amount\n",
        "    asset_ratio = (property_value + investments) / max(income * 12, 1)\n",
        "    financial_base = (\n",
        "        min(np.log(income/20000) * 12, 25) +\n",
        "        min(asset_ratio * 20, 30) +\n",
        "        max(0, savings_ratio * 25) +\n",
        "        min(bank_years * 1.5, 15)\n",
        "    )\n",
        "    # Consider application amount in financial health assessment\n",
        "    financial_penalty = (dti_ratio * 20 +\n",
        "                        max(0, expense_ratio - 0.75) * 18 +\n",
        "                        max(0, application_to_income_ratio - 1.8) * 10)  # Over-application indicates poor planning\n",
        "    financial_score = _clip_local(int(financial_base - financial_penalty + np.random.randint(-10, 11)), 10, 95)\n",
        "\n",
        "    # 4. PAYMENT RELIABILITY SCORE (10-95) - Enhanced with loan behavior\n",
        "    reliability_base = (\n",
        "        min(emp_years * 4, 35) +\n",
        "        max(0, (1 - expense_ratio) * 30) +\n",
        "        min(income/5000, 20) +\n",
        "        10\n",
        "    )\n",
        "    # Reliability affected by loan application vs utilization pattern\n",
        "    reliability_penalty = (dti_ratio * 30 +\n",
        "                          max(0, expense_ratio - 0.85) * 25 +\n",
        "                          abs(loan_utilization_ratio - 0.7) * 8)  # Optimal utilization around 70%\n",
        "    reliability_score = _clip_local(int(reliability_base - reliability_penalty + np.random.randint(-7, 8)), 10, 95)\n",
        "\n",
        "    # 5. STABILITY INDEX (5-90) - Include application amount pattern\n",
        "    stability_base = (\n",
        "        min(emp_years * 3, 25) +\n",
        "        min(bank_years * 2, 15) +\n",
        "        min((age - 20) * 0.6, 20) +\n",
        "        min(asset_ratio * 15, 20) +\n",
        "        10\n",
        "    )\n",
        "    # Stability considers reasonable application amounts\n",
        "    stability_penalty = (dti_ratio * 18 +\n",
        "                        max(0, expense_ratio - 0.8) * 12 +\n",
        "                        max(0, application_to_income_ratio - 2.5) * 8)  # Very high applications indicate instability\n",
        "    stability_score = _clip_local(int(stability_base - stability_penalty + np.random.randint(-12, 13)), 5, 90)\n",
        "\n",
        "    # 6. UTILITY PAYMENT REGULARITY SCORE (25-95) - Enhanced\n",
        "    utility_base = (\n",
        "        85 -\n",
        "        dti_ratio * 25 -\n",
        "        max(0, expense_ratio - 0.6) * 20 +\n",
        "        min(savings_ratio * 15, 10)\n",
        "    )\n",
        "    utility_score = _clip_local(int(utility_base + np.random.randint(-8, 9)), 25, 95)\n",
        "\n",
        "    # 7. LOCATION STABILITY SCORE (30-120) - Enhanced\n",
        "    location_base = (\n",
        "        bank_years * 8 +\n",
        "        emp_years * 5 +\n",
        "        (1 if property_value > 0 else 0) * 15 +\n",
        "        min((age - 18) * 1.2, 25) +\n",
        "        30\n",
        "    )\n",
        "    location_score = _clip_local(int(location_base + np.random.randint(-10, 11)), 30, 120)\n",
        "\n",
        "    return {\n",
        "        \"timeliness_score\": timeliness_score,\n",
        "        \"repayment_ability_score\": repayment_score,\n",
        "        \"financial_health_score\": financial_score,\n",
        "        \"payment_reliability_score\": reliability_score,\n",
        "        \"stability_index\": stability_score,\n",
        "        \"utility_payment_regularity_score\": utility_score,\n",
        "        \"location_stability_score\": location_score\n",
        "    }\n",
        "\n",
        "def _pd_from_features(row):\n",
        "    \"\"\"\n",
        "    Enhanced probability of default calculation including loan application amount\n",
        "    \"\"\"\n",
        "    income = max(1.0, float(row[\"monthly_income_inr\"]))\n",
        "    expenses = float(row[\"monthly_expenses_inr\"])\n",
        "    loan_amount = float(row[\"outstanding_loan_amount_inr\"])\n",
        "    application_amount = float(row[\"loan_amount_applied_inr\"])  # NEW\n",
        "\n",
        "    dti = loan_amount / (12.0 * income)\n",
        "    app_to_income = application_amount / (12.0 * income)  # NEW RATIO\n",
        "    exp_ratio = expenses / income\n",
        "\n",
        "    s_avg = np.mean([\n",
        "        _clip(row[\"timeliness_score\"], 0, 100),\n",
        "        _clip(row[\"repayment_ability_score\"], 0, 100),\n",
        "        _clip(row[\"financial_health_score\"], 0, 100),\n",
        "        _clip(row[\"payment_reliability_score\"], 0, 100),\n",
        "        _clip(row[\"stability_index\"], 0, 100),\n",
        "    ]) / 100.0\n",
        "\n",
        "    tenure = max(0.0, float(row[\"years_current_employment\"]))\n",
        "    bank_rel = max(0.0, float(row[\"banking_relationship_years\"]))\n",
        "    age = int(row[\"age\"])\n",
        "\n",
        "    # Enhanced probability calculation with application amount factor\n",
        "    x = (\n",
        "        1.6 * dti +\n",
        "        1.1 * exp_ratio +\n",
        "        0.4 * app_to_income +  # NEW: Application amount impact on default probability\n",
        "        -2.2 * s_avg +\n",
        "        -0.18 * np.log1p(tenure) +\n",
        "        -0.22 * np.log1p(bank_rel) +\n",
        "        0.06 * (age < 25) +\n",
        "        0.04 * (age > 60) +\n",
        "        0.07 * _sigmoid((income - 100000.0) / 50000.0) * (dti > 0.7) +\n",
        "        0.05 * (app_to_income > 3.0) - 0.3  # NEW: Penalty for excessive applications\n",
        "    )\n",
        "\n",
        "    edu = row.get(\"education_level\", \"Graduate\")\n",
        "    x += {\"High School\": 0.05, \"Diploma\": 0.02, \"Graduate\": -0.01, \"Post Graduate\": -0.03, \"Professional\": -0.05}.get(edu, 0.0)\n",
        "    emp = row.get(\"employment_type\", \"Salaried\")\n",
        "    x += {\"Salaried\": -0.02, \"Professional\": -0.03, \"Self Employed\": 0.03, \"Business Owner\": 0.01}.get(emp, 0.0)\n",
        "\n",
        "    # NEW: Light locality effect for improved model accuracy\n",
        "    loc = row.get(\"location_type\", \"Tier2\")\n",
        "    x += {\"Metro\": -0.03, \"Tier1\": 0.00, \"Tier2\": 0.02}.get(loc, 0.0)\n",
        "\n",
        "    base_pd = _sigmoid(x)\n",
        "    pd = _clip(float(base_pd + np.random.normal(0, 0.08)), 0.01, 0.92)\n",
        "    return pd\n",
        "\n",
        "def _generate_profile(segment, age_mu=36, inc_mu=55000, inc_sigma=30000):\n",
        "    if segment == \"excellent\":\n",
        "        # Use sampled base values and adjust for segment\n",
        "        age = max(28, min(65, _sample_age() + 5))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(60000, base_income * 1.5))\n",
        "        exp_ratio = np.clip(np.random.normal(0.42, 0.09), 0.25, 0.62)\n",
        "        dti = np.clip(np.random.normal(0.18, 0.07), 0.02, 0.38)\n",
        "        education = np.random.choice([\"Graduate\", \"Post Graduate\", \"Professional\"], p=[0.3, 0.5, 0.2])\n",
        "        employment = np.random.choice([\"Salaried\", \"Professional\", \"Business Owner\"], p=[0.4, 0.4, 0.2])\n",
        "    elif segment == \"good\":\n",
        "        age = max(25, min(58, _sample_age() + 2))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(40000, base_income * 1.15))\n",
        "        exp_ratio = np.clip(np.random.normal(0.57, 0.11), 0.38, 0.78)\n",
        "        dti = np.clip(np.random.normal(0.38, 0.13), 0.08, 0.72)\n",
        "        education = np.random.choice([\"Diploma\", \"Graduate\", \"Post Graduate\"], p=[0.2, 0.6, 0.2])\n",
        "        employment = np.random.choice([\"Salaried\", \"Professional\", \"Self Employed\"], p=[0.5, 0.3, 0.2])\n",
        "    elif segment == \"fair\":\n",
        "        age = max(22, min(55, _sample_age() - 1))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(25000, base_income * 0.88))\n",
        "        exp_ratio = np.clip(np.random.normal(0.72, 0.12), 0.52, 0.88)\n",
        "        dti = np.clip(np.random.normal(0.65, 0.22), 0.28, 1.25)\n",
        "        education = np.random.choice([\"High School\", \"Diploma\", \"Graduate\"], p=[0.3, 0.5, 0.2])\n",
        "        employment = np.random.choice([\"Salaried\", \"Self Employed\"], p=[0.6, 0.4])\n",
        "    elif segment == \"poor\":\n",
        "        age = max(20, min(52, _sample_age() - 3))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(18000, base_income * 0.65))\n",
        "        exp_ratio = np.clip(np.random.normal(0.83, 0.09), 0.68, 0.97)\n",
        "        dti = np.clip(np.random.normal(1.15, 0.38), 0.65, 2.2)\n",
        "        education = np.random.choice([\"High School\", \"Diploma\"], p=[0.7, 0.3])\n",
        "        employment = np.random.choice([\"Salaried\", \"Self Employed\"], p=[0.4, 0.6])\n",
        "    else:  # bad\n",
        "        age = max(18, min(48, _sample_age() - 5))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(15000, base_income * 0.52))\n",
        "        exp_ratio = np.clip(np.random.normal(0.92, 0.07), 0.78, 1.00)\n",
        "        dti = np.clip(np.random.normal(1.85, 0.55), 1.1, 3.8)\n",
        "        education = np.random.choice([\"High School\", \"Diploma\"], p=[0.8, 0.2])\n",
        "        employment = \"Self Employed\"\n",
        "\n",
        "    gender = np.random.choice([\"Male\", \"Female\"], p=[0.55, 0.45])\n",
        "    marital_status = np.random.choice([\"Single\", \"Married\"], p=[0.25, 0.75]) if age >= 28 else np.random.choice([\"Single\", \"Married\"], p=[0.7, 0.3])\n",
        "    if marital_status == \"Married\":\n",
        "        family_size = np.random.randint(2, 6)\n",
        "        dependents = max(0, family_size - 2)\n",
        "        spouse_income = int(np.random.uniform(0.2, 0.8) * income) if np.random.rand() < 0.6 else 0\n",
        "    else:\n",
        "        family_size, dependents, spouse_income = 1, 0, 0\n",
        "\n",
        "    # CHANGED: Use deterministic city-to-location mapping\n",
        "    city = np.random.choice(GUJARAT_CITIES)\n",
        "    location_type = CITY_TO_LOCATION_TYPE.get(city, \"Tier2\")\n",
        "\n",
        "    expenses = int(_clip(income * exp_ratio + np.random.randint(-3000, 3000), 2000, max(2500, income - 500)))\n",
        "    savings = max(0, income - expenses - np.random.randint(0, 4000))\n",
        "\n",
        "    # Asset generation (needed for loan application calculation)\n",
        "    if income > 80000 and age > 30:\n",
        "        property_value = int(income * np.random.uniform(25, 55) * (age / 40))\n",
        "        vehicle_value = int(income * np.random.uniform(2, 8))\n",
        "        investments = int(income * np.random.uniform(8, 25) * ((age - 25) / 20))\n",
        "    elif income > 50000:\n",
        "        property_value = int(income * np.random.uniform(15, 35) * (age / 40)) if np.random.rand() < 0.4 else 0\n",
        "        vehicle_value = int(income * np.random.uniform(1, 5)) if np.random.rand() < 0.6 else 0\n",
        "        investments = int(income * np.random.uniform(3, 12)) if np.random.rand() < 0.5 else 0\n",
        "    else:\n",
        "        property_value = 0\n",
        "        vehicle_value = int(income * np.random.uniform(0.5, 3)) if np.random.rand() < 0.3 else 0\n",
        "        investments = int(income * np.random.uniform(0.5, 5)) if np.random.rand() < 0.2 else 0\n",
        "\n",
        "    # Generate loan application amount FIRST (needed for outstanding loan calculation)\n",
        "    loan_application_amount = _generate_loan_application_amount(\n",
        "        income, age, segment, property_value, employment\n",
        "    )\n",
        "\n",
        "    # Outstanding loan amount is typically less than or equal to application amount\n",
        "    utilization_rate = np.clip(np.random.beta(2, 2), 0.3, 1.0)  # Most people use 30-100% of approved amount\n",
        "    loan_amt = int(loan_application_amount * utilization_rate)\n",
        "\n",
        "    # Ensure DTI constraints are still met\n",
        "    max_affordable_loan = int(dti * 12 * income)\n",
        "    loan_amt = min(loan_amt, max_affordable_loan)\n",
        "    loan_amt = max(15000, loan_amt)  # Minimum loan amount\n",
        "\n",
        "    # Use sampled utility bills\n",
        "    utility_bills = _sample_monthly_charges()\n",
        "    utility_bills = int(utility_bills * family_size * np.random.uniform(0.8, 1.2))\n",
        "\n",
        "    # Use sampled tenure values\n",
        "    emp_years = round(_clip(_sample_tenure() * np.random.uniform(0.6, 1.0), 0.5, 35), 1)\n",
        "    bank_years = round(_clip(_sample_tenure() - np.random.uniform(-2.0, 3.0), 0.5, max(0.5, age - 18)), 1)\n",
        "\n",
        "    if employment in [\"Business Owner\", \"Self Employed\"]:\n",
        "        business_revenue = int(income * np.random.uniform(1.2, 2.8))\n",
        "    else:\n",
        "        business_revenue = 0\n",
        "\n",
        "    if age < 35 and education in [\"Graduate\", \"Post Graduate\", \"Professional\"]:\n",
        "        mobile_hours = round(np.random.uniform(6, 12), 1)\n",
        "        digital_transactions = _sample_digital_transactions() + np.random.randint(20, 40)\n",
        "        social_media = np.random.randint(4, 8)\n",
        "        app_usage_score = np.random.randint(65, 95)\n",
        "        digital_payment_score = np.random.randint(70, 95)\n",
        "        mobile_banking_score = np.random.randint(60, 90)\n",
        "    elif age < 50:\n",
        "        mobile_hours = round(np.random.uniform(3, 8), 1)\n",
        "        digital_transactions = _sample_digital_transactions()\n",
        "        social_media = np.random.randint(2, 6)\n",
        "        app_usage_score = np.random.randint(40, 75)\n",
        "        digital_payment_score = np.random.randint(45, 80)\n",
        "        mobile_banking_score = np.random.randint(35, 70)\n",
        "    else:\n",
        "        mobile_hours = round(np.random.uniform(1, 5), 1)\n",
        "        digital_transactions = max(10, _sample_digital_transactions() - 20)\n",
        "        social_media = np.random.randint(1, 4)\n",
        "        app_usage_score = np.random.randint(20, 55)\n",
        "        digital_payment_score = np.random.randint(25, 60)\n",
        "        mobile_banking_score = np.random.randint(20, 50)\n",
        "\n",
        "    avg_transaction = int((income + expenses) / max(1, digital_transactions) * np.random.uniform(0.5, 2.0))\n",
        "\n",
        "    # Create the initial row with basic financial data\n",
        "    row = {\n",
        "        \"applicant_id\": _generate_applicant_id(),\n",
        "        \"application_date\": _generate_application_date(),\n",
        "        \"age\": age,\n",
        "        \"gender\": gender,\n",
        "        \"education_level\": education,\n",
        "        \"employment_type\": employment,\n",
        "        \"marital_status\": marital_status,\n",
        "        \"family_size\": family_size,\n",
        "        \"number_of_dependents\": dependents,\n",
        "        \"location_type\": location_type,\n",
        "        \"monthly_income_inr\": income,\n",
        "        \"spouse_income_inr\": spouse_income,\n",
        "        \"monthly_expenses_inr\": expenses,\n",
        "        \"monthly_savings_inr\": savings,\n",
        "        \"monthly_utility_bills_inr\": utility_bills,\n",
        "        \"property_value_inr\": property_value,\n",
        "        \"vehicle_value_inr\": vehicle_value,\n",
        "        \"total_investments_inr\": investments,\n",
        "        \"outstanding_loan_amount_inr\": loan_amt,\n",
        "        \"loan_amount_applied_inr\": loan_application_amount,  # NEW COLUMN\n",
        "        \"years_current_employment\": emp_years,\n",
        "        \"banking_relationship_years\": bank_years,\n",
        "        \"monthly_business_revenue_inr\": business_revenue,\n",
        "        \"daily_mobile_hours\": mobile_hours,\n",
        "        \"monthly_digital_transactions\": digital_transactions,\n",
        "        \"avg_transaction_amount_inr\": avg_transaction,\n",
        "        \"social_media_accounts_count\": social_media,\n",
        "        \"mobile_app_usage_intensity_score\": app_usage_score,\n",
        "        \"digital_payment_adoption_score\": digital_payment_score,\n",
        "        \"mobile_banking_usage_score\": mobile_banking_score,\n",
        "        \"data_completeness_pct\": np.random.randint(85, 100),\n",
        "        \"consent_status\": \"Full Consent\",\n",
        "        \"explainability_support_flag\": 1,\n",
        "        \"city\": city,\n",
        "    }\n",
        "\n",
        "    # Calculate data-driven scores based on actual financial data\n",
        "    scores = calculate_data_driven_scores(row)\n",
        "\n",
        "    # Update the row with calculated scores\n",
        "    row.update(scores)\n",
        "\n",
        "    # Calculate probability of default using the new scores\n",
        "    pd_val = _pd_from_features(row)\n",
        "    row[\"probability_of_default\"] = pd_val\n",
        "    row[\"risk_category\"] = _risk_category_from_p(pd_val)\n",
        "\n",
        "    return row\n",
        "\n",
        "def generate_enhanced_training_data(n_rows=12000, seed=111):\n",
        "    np.random.seed(seed)\n",
        "    seg_mix = {\"excellent\": 0.28, \"good\": 0.32, \"fair\": 0.24, \"poor\": 0.11, \"bad\": 0.05}\n",
        "    counts = {k: int(v * n_rows) for k, v in seg_mix.items()}\n",
        "    diff = n_rows - sum(counts.values())\n",
        "    if diff != 0:\n",
        "        counts[\"good\"] += diff\n",
        "\n",
        "    rows = []\n",
        "    for seg, cnt in counts.items():\n",
        "        for _ in range(cnt):\n",
        "            rows.append(_generate_profile(seg))\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df[ALL_COLUMNS]\n",
        "    out_csv = os.path.join(OUT_DIR, \"training_data_aligned.csv\")\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f\"[TRAIN] ✅ Enhanced training set: {out_csv} shape={df.shape}\")\n",
        "    print(f\"[TRAIN] Risk distribution: {df['risk_category'].value_counts().to_dict()}\")\n",
        "    print(f\"[TRAIN] PD range: {df['probability_of_default'].min():.3f} - {df['probability_of_default'].max():.3f}\")\n",
        "    print(f\"[TRAIN] Application amount range: ₹{df['loan_amount_applied_inr'].min():,.0f} - ₹{df['loan_amount_applied_inr'].max():,.0f}\")\n",
        "\n",
        "    # Print dataset integration summary\n",
        "    print(f\"\\n[INFO] Dataset Integration Summary:\")\n",
        "    print(f\"  - Loan dataset: {'✅ Loaded' if loan_df is not None else '❌ Not found'}\")\n",
        "    print(f\"  - Telco dataset: {'✅ Loaded' if telco_df is not None else '❌ Not found'}\")\n",
        "    if loan_df is not None:\n",
        "        print(f\"  - Age sampling: μ={loan_age_stats['mean']:.1f}, σ={loan_age_stats['std']:.1f}\" if loan_age_stats is not None else \"\")\n",
        "        print(f\"  - Income sampling: μ={loan_income_stats['mean']:.0f}, σ={loan_income_stats['std']:.0f}\" if loan_income_stats is not None else \"\")\n",
        "        print(f\"  - Loan amount sampling: μ={loan_amount_stats['mean']:.0f}, σ={loan_amount_stats['std']:.0f}\" if loan_amount_stats is not None else \"\")\n",
        "    if telco_df is not None:\n",
        "        print(f\"  - Tenure sampling: μ={telco_tenure_stats['mean']:.1f}, σ={telco_tenure_stats['std']:.1f}\" if telco_tenure_stats is not None else \"\")\n",
        "        print(f\"  - Charges sampling: μ={telco_charges_stats['mean']:.1f}, σ={telco_charges_stats['std']:.1f}\" if telco_charges_stats is not None else \"\")\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_enhanced_training_data(n_rows=12000, seed=111)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Test data generator (preserves exact columns; writes test_data_aligned.csv)\n",
        "# ALIGNED with enhanced training data generator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "np.random.seed(222)\n",
        "\n",
        "OUT_DIR = \"credit_risk_output\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "#  NEW: Load external reference datasets (same as training)\n",
        "# -------------------------------\n",
        "LOAN_DATA_PATH = \"Loan_default (1).csv\"\n",
        "TELCO_DATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "# Safe loading with error handling\n",
        "try:\n",
        "    loan_df = pd.read_csv(LOAN_DATA_PATH)\n",
        "    print(f\"[INFO] Loaded loan dataset for test: {loan_df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[WARNING] {LOAN_DATA_PATH} not found. Using fallback distributions.\")\n",
        "    loan_df = None\n",
        "\n",
        "try:\n",
        "    telco_df = pd.read_csv(TELCO_DATA_PATH)\n",
        "    print(f\"[INFO] Loaded telco dataset for test: {telco_df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[WARNING] {TELCO_DATA_PATH} not found. Using fallback distributions.\")\n",
        "    telco_df = None\n",
        "\n",
        "# Pre-calculate distributions from external datasets (same as training)\n",
        "if loan_df is not None:\n",
        "    loan_age_stats = loan_df[\"age\"].dropna().describe() if \"age\" in loan_df.columns else None\n",
        "    loan_income_stats = loan_df[\"income\"].dropna().describe() if \"income\" in loan_df.columns else None\n",
        "    loan_amount_stats = loan_df[\"loan_amount\"].dropna().describe() if \"loan_amount\" in loan_df.columns else None\n",
        "else:\n",
        "    loan_age_stats = loan_income_stats = loan_amount_stats = None\n",
        "\n",
        "if telco_df is not None:\n",
        "    telco_tenure_stats = telco_df[\"tenure\"].dropna().describe() if \"tenure\" in telco_df.columns else None\n",
        "    telco_charges_stats = telco_df[\"MonthlyCharges\"].dropna().describe() if \"MonthlyCharges\" in telco_df.columns else None\n",
        "else:\n",
        "    telco_tenure_stats = telco_charges_stats = None\n",
        "\n",
        "# Test columns (NO targets, NO scores - these should be predicted) - UPDATED with loan application amount\n",
        "TEST_COLUMNS = [\n",
        "    \"applicant_id\", \"application_date\", \"age\", \"gender\", \"education_level\",\n",
        "    \"employment_type\", \"marital_status\", \"family_size\", \"number_of_dependents\",\n",
        "    \"location_type\", \"monthly_income_inr\", \"spouse_income_inr\", \"monthly_expenses_inr\",\n",
        "    \"monthly_savings_inr\", \"monthly_utility_bills_inr\", \"property_value_inr\",\n",
        "    \"vehicle_value_inr\", \"total_investments_inr\", \"outstanding_loan_amount_inr\",\n",
        "    \"loan_amount_applied_inr\", \"years_current_employment\", \"banking_relationship_years\",\n",
        "    \"monthly_business_revenue_inr\", \"daily_mobile_hours\", \"monthly_digital_transactions\",\n",
        "    \"avg_transaction_amount_inr\", \"social_media_accounts_count\", \"mobile_app_usage_intensity_score\",\n",
        "    \"digital_payment_adoption_score\", \"data_completeness_pct\", \"consent_status\",\n",
        "    \"explainability_support_flag\", \"city\"\n",
        "]\n",
        "\n",
        "GUJARAT_CITIES = [\n",
        "    \"Ahmedabad\", \"Surat\", \"Vadodara\", \"Rajkot\", \"Bhavnagar\", \"Jamnagar\", \"Junagadh\",\n",
        "    \"Gandhinagar\", \"Nadiad\", \"Morbi\", \"Anand\", \"Mehsana\", \"Navsari\", \"Bharuch\",\n",
        "    \"Vapi\", \"Valsad\", \"Patan\", \"Godhra\", \"Porbandar\", \"Palanpur\", \"Veraval\", \"Surendranagar\"\n",
        "]\n",
        "EDUCATION_LEVELS = [\"High School\", \"Diploma\", \"Graduate\", \"Post Graduate\", \"Professional\"]\n",
        "EMPLOYMENT_TYPES = [\"Salaried\", \"Self Employed\", \"Business Owner\", \"Professional\"]\n",
        "LOCATION_TYPES = [\"Metro\", \"Tier1\", \"Tier2\"]\n",
        "\n",
        "# NEW: City to location type mapping as specified (same as training)\n",
        "CITY_TO_LOCATION_TYPE = {\n",
        "    \"Ahmedabad\": \"Metro\",\n",
        "    \"Surat\": \"Metro\",\n",
        "    \"Vadodara\": \"Metro\",\n",
        "    \"Rajkot\": \"Tier1\",\n",
        "    \"Bhavnagar\": \"Tier1\",\n",
        "    \"Jamnagar\": \"Tier1\",\n",
        "    \"Junagadh\": \"Tier2\",\n",
        "    \"Gandhinagar\": \"Metro\",\n",
        "    \"Nadiad\": \"Tier2\",\n",
        "    \"Morbi\": \"Tier2\",\n",
        "    \"Anand\": \"Tier2\",\n",
        "    \"Mehsana\": \"Tier2\",\n",
        "    \"Navsari\": \"Tier2\",\n",
        "    \"Bharuch\": \"Tier2\",\n",
        "    \"Vapi\": \"Tier2\",\n",
        "    \"Valsad\": \"Tier2\",\n",
        "    \"Patan\": \"Tier2\",\n",
        "    \"Godhra\": \"Tier2\",\n",
        "    \"Porbandar\": \"Tier2\",\n",
        "    \"Palanpur\": \"Tier2\",\n",
        "    \"Veraval\": \"Tier2\",\n",
        "    \"Surendranagar\": \"Tier1\"\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# NEW: Sampling functions (same as training)\n",
        "# -------------------------------\n",
        "def _sample_age():\n",
        "    \"\"\"Sample age from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_age_stats is not None:\n",
        "        sampled_age = int(np.random.normal(loan_age_stats[\"mean\"], loan_age_stats[\"std\"]))\n",
        "        return max(18, min(75, sampled_age))\n",
        "    else:\n",
        "        return int(np.random.normal(36, 12))\n",
        "\n",
        "def _sample_income():\n",
        "    \"\"\"Sample income from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_income_stats is not None:\n",
        "        sampled_income = int(np.random.normal(loan_income_stats[\"mean\"], loan_income_stats[\"std\"]))\n",
        "        return max(15000, min(500000, sampled_income))\n",
        "    else:\n",
        "        return int(np.random.normal(55000, 25000))\n",
        "\n",
        "def _sample_loan_amount():\n",
        "    \"\"\"Sample loan amount from loan dataset or fallback to original distribution\"\"\"\n",
        "    if loan_amount_stats is not None:\n",
        "        sampled_amount = int(np.random.normal(loan_amount_stats[\"mean\"], loan_amount_stats[\"std\"]))\n",
        "        return max(15000, min(6000000, sampled_amount))\n",
        "    else:\n",
        "        return int(np.random.normal(250000, 80000))\n",
        "\n",
        "def _sample_tenure():\n",
        "    \"\"\"Sample tenure/relationship years from telco dataset or fallback\"\"\"\n",
        "    if telco_tenure_stats is not None:\n",
        "        sampled_tenure = np.random.normal(telco_tenure_stats[\"mean\"], telco_tenure_stats[\"std\"])\n",
        "        return max(0.5, min(35.0, sampled_tenure))\n",
        "    else:\n",
        "        return np.random.uniform(0.5, 15.0)\n",
        "\n",
        "def _sample_digital_transactions():\n",
        "    \"\"\"Sample digital transaction count based on telco usage patterns\"\"\"\n",
        "    if telco_charges_stats is not None:\n",
        "        base_transactions = int(telco_charges_stats[\"mean\"] / 2)\n",
        "        noise = np.random.normal(0, telco_charges_stats[\"std\"] / 4)\n",
        "        return max(5, int(base_transactions + noise))\n",
        "    else:\n",
        "        base = int(np.random.normal(60, 20))\n",
        "        return max(5, base)\n",
        "\n",
        "def _sample_monthly_charges():\n",
        "    \"\"\"Sample monthly charges/utility bills from telco dataset\"\"\"\n",
        "    if telco_charges_stats is not None:\n",
        "        charges = np.random.normal(telco_charges_stats[\"mean\"], telco_charges_stats[\"std\"])\n",
        "        return max(500, int(charges * 60))  # Convert USD to INR approximately\n",
        "    else:\n",
        "        return int(np.random.normal(2500, 800))\n",
        "\n",
        "# -------------------------------\n",
        "# NEW: Function to generate realistic loan application amount (same as training)\n",
        "# -------------------------------\n",
        "def _generate_loan_application_amount(income, age, profile_type, property_value, employment_type):\n",
        "    \"\"\"\n",
        "    Generate realistic loan application amount based on customer profile\n",
        "    \"\"\"\n",
        "    # Base application amount from dataset sampling\n",
        "    base_amount = _sample_loan_amount()\n",
        "\n",
        "    # Income-based adjustment (higher income = higher applications)\n",
        "    income_multiplier = min(3.0, max(0.3, income / 50000))\n",
        "\n",
        "    # Age-based loan purpose patterns\n",
        "    if age < 30:\n",
        "        purpose_multiplier = np.random.choice([0.6, 1.2, 2.0], p=[0.5, 0.3, 0.2])\n",
        "    elif age < 45:\n",
        "        purpose_multiplier = np.random.choice([1.0, 2.5, 4.0], p=[0.3, 0.4, 0.3])\n",
        "    else:\n",
        "        purpose_multiplier = np.random.choice([0.8, 1.8, 3.0], p=[0.4, 0.4, 0.2])\n",
        "\n",
        "    # Property ownership influence\n",
        "    if property_value > 0:\n",
        "        property_multiplier = np.random.uniform(1.2, 2.0)\n",
        "    else:\n",
        "        property_multiplier = np.random.uniform(0.7, 1.3)\n",
        "\n",
        "    # Employment type influence\n",
        "    employment_multipliers = {\n",
        "        \"Salaried\": np.random.uniform(0.8, 1.4),\n",
        "        \"Professional\": np.random.uniform(1.0, 1.8),\n",
        "        \"Business Owner\": np.random.uniform(1.2, 2.5),\n",
        "        \"Self Employed\": np.random.uniform(0.6, 1.6)\n",
        "    }\n",
        "    emp_multiplier = employment_multipliers.get(employment_type, 1.0)\n",
        "\n",
        "    # Profile-based adjustments\n",
        "    profile_adjustments = {\n",
        "        \"high_earner_low_risk\": np.random.uniform(2.0, 3.5),\n",
        "        \"stable_middle_class\": np.random.uniform(1.2, 2.2),\n",
        "        \"young_professional\": np.random.uniform(0.8, 1.8),\n",
        "        \"average_earner\": np.random.uniform(0.6, 1.4),\n",
        "        \"financial_stress\": np.random.uniform(0.3, 0.9),\n",
        "        \"outlier_case\": np.random.uniform(1.5, 3.0)\n",
        "    }\n",
        "    profile_multiplier = profile_adjustments.get(profile_type, 1.0)\n",
        "\n",
        "    # Calculate final application amount\n",
        "    application_amount = int(base_amount * income_multiplier * purpose_multiplier *\n",
        "                           property_multiplier * emp_multiplier * profile_multiplier)\n",
        "\n",
        "    # Realistic bounds\n",
        "    min_amount = 20000\n",
        "    max_amount = min(2000000, int(income * 12 * 8))\n",
        "\n",
        "    return max(min_amount, min(max_amount, application_amount))\n",
        "\n",
        "# -------------------------------\n",
        "# Utility functions\n",
        "# -------------------------------\n",
        "def _clip(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def _generate_applicant_id():\n",
        "    prefix = np.random.choice([\"A\", \"B\", \"C\",\"D\", \"E\", \"F\"])\n",
        "    number = np.random.randint(1000, 9999)\n",
        "    return f\"{prefix}{number:04d}\"\n",
        "\n",
        "def _generate_application_date():\n",
        "    start_date = datetime(2024, 6, 1)\n",
        "    end_date = datetime(2025, 7, 31)\n",
        "    days_diff = (end_date - start_date).days\n",
        "    random_days = np.random.randint(0, max(1, days_diff))\n",
        "    return (start_date + timedelta(days=int(random_days))).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def _generate_test_profile(profile_type):\n",
        "    \"\"\"\n",
        "    Generate test profiles using same logic as training but with external dataset sampling\n",
        "    NO SCORES OR TARGETS - those should be predicted by the model\n",
        "    \"\"\"\n",
        "    if profile_type == \"high_earner_low_risk\":\n",
        "        age = max(32, min(55, _sample_age() + 5))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(120000, base_income * 1.8))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.35, 0.08), 0.20, 0.55))\n",
        "        education = np.random.choice([\"Graduate\", \"Post Graduate\", \"Professional\"], p=[0.2, 0.5, 0.3])\n",
        "        employment = np.random.choice([\"Salaried\", \"Professional\", \"Business Owner\"], p=[0.3, 0.4, 0.3])\n",
        "\n",
        "    elif profile_type == \"stable_middle_class\":\n",
        "        age = max(28, min(50, _sample_age() + 2))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(60000, base_income * 1.3))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.48, 0.09), 0.32, 0.68))\n",
        "        education = np.random.choice([\"Diploma\", \"Graduate\", \"Post Graduate\"], p=[0.3, 0.5, 0.2])\n",
        "        employment = np.random.choice([\"Salaried\", \"Professional\"], p=[0.7, 0.3])\n",
        "\n",
        "    elif profile_type == \"young_professional\":\n",
        "        age = max(22, min(32, _sample_age() - 5))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(45000, base_income * 1.1))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.58, 0.12), 0.38, 0.75))\n",
        "        education = np.random.choice([\"Graduate\", \"Post Graduate\"], p=[0.7, 0.3])\n",
        "        employment = np.random.choice([\"Salaried\", \"Professional\"], p=[0.8, 0.2])\n",
        "\n",
        "    elif profile_type == \"average_earner\":\n",
        "        age = max(25, min(48, _sample_age()))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(35000, base_income * 0.9))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.68, 0.12), 0.48, 0.85))\n",
        "        education = np.random.choice([\"High School\", \"Diploma\", \"Graduate\"], p=[0.2, 0.5, 0.3])\n",
        "        employment = np.random.choice([\"Salaried\", \"Self Employed\"], p=[0.6, 0.4])\n",
        "\n",
        "    elif profile_type == \"financial_stress\":\n",
        "        age = max(22, min(45, _sample_age() - 2))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(22000, base_income * 0.7))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.85, 0.08), 0.75, 0.95))\n",
        "        education = np.random.choice([\"High School\", \"Diploma\", \"Graduate\"], p=[0.4, 0.4, 0.2])\n",
        "        employment = np.random.choice([\"Salaried\", \"Self Employed\"], p=[0.5, 0.5])\n",
        "\n",
        "    else:  # outlier_case\n",
        "        age = max(20, min(65, _sample_age() + np.random.randint(-10, 10)))\n",
        "        base_income = _sample_income()\n",
        "        income = int(max(18000, base_income * np.random.uniform(0.5, 2.0)))\n",
        "        exp_ratio = float(np.clip(np.random.normal(0.65, 0.25), 0.25, 0.95))\n",
        "        education = np.random.choice(EDUCATION_LEVELS)\n",
        "        employment = np.random.choice(EMPLOYMENT_TYPES)\n",
        "\n",
        "    # Demographics\n",
        "    gender = np.random.choice([\"Male\", \"Female\"], p=[0.55, 0.45])\n",
        "    marital_status = np.random.choice([\"Single\", \"Married\"], p=[0.3, 0.7]) if age >= 28 else np.random.choice([\"Single\", \"Married\"], p=[0.75, 0.25])\n",
        "\n",
        "    if marital_status == \"Married\":\n",
        "        family_size = np.random.randint(2, 5)\n",
        "        dependents = max(0, family_size - 2)\n",
        "        spouse_income = int(np.random.uniform(0.15, 0.75) * income) if np.random.rand() < 0.65 else 0\n",
        "    else:\n",
        "        family_size, dependents, spouse_income = 1, 0, 0\n",
        "\n",
        "    # CHANGED: Use deterministic city-to-location mapping\n",
        "    city = np.random.choice(GUJARAT_CITIES)\n",
        "    location_type = CITY_TO_LOCATION_TYPE.get(city, \"Tier2\")\n",
        "\n",
        "    # Financial calculations\n",
        "    expenses = int(_clip(income * exp_ratio + np.random.randint(-2500, 2500), 1500, max(2000, income - 300)))\n",
        "    savings = max(0, income - expenses - np.random.randint(0, 3500))\n",
        "\n",
        "    # Assets\n",
        "    if income > 90000 and age > 32:\n",
        "        property_value = int(income * np.random.uniform(20, 45) * (age / 40))\n",
        "        vehicle_value = int(income * np.random.uniform(1.5, 6))\n",
        "        investments = int(income * np.random.uniform(6, 20) * ((age - 22) / 18))\n",
        "    elif income > 45000:\n",
        "        property_value = int(income * np.random.uniform(10, 25) * (age / 40)) if np.random.rand() < 0.35 else 0\n",
        "        vehicle_value = int(income * np.random.uniform(0.8, 4)) if np.random.rand() < 0.55 else 0\n",
        "        investments = int(income * np.random.uniform(2, 10)) if np.random.rand() < 0.45 else 0\n",
        "    else:\n",
        "        property_value = 0\n",
        "        vehicle_value = int(income * np.random.uniform(0.3, 2.5)) if np.random.rand() < 0.25 else 0\n",
        "        investments = int(income * np.random.uniform(0.2, 4)) if np.random.rand() < 0.15 else 0\n",
        "\n",
        "    # Generate loan application amount FIRST\n",
        "    loan_application_amount = _generate_loan_application_amount(\n",
        "        income, age, profile_type, property_value, employment\n",
        "    )\n",
        "\n",
        "    # Outstanding loan calculation\n",
        "    utilization_rate = np.clip(np.random.beta(2.5, 2), 0.25, 1.0)\n",
        "    outstanding_loan = int(loan_application_amount * utilization_rate)\n",
        "\n",
        "    # Keep reasonable bounds\n",
        "    max_reasonable_loan = int(income * 12 * 3.5)  # Max 3.5x annual income\n",
        "    outstanding_loan = min(outstanding_loan, max_reasonable_loan)\n",
        "    outstanding_loan = max(10000, outstanding_loan)\n",
        "\n",
        "    # Utility bills\n",
        "    utility_bills = _sample_monthly_charges()\n",
        "    utility_bills = int(utility_bills * family_size * np.random.uniform(0.7, 1.3))\n",
        "\n",
        "    # Employment and banking tenure\n",
        "    emp_years = round(_clip(_sample_tenure() * np.random.uniform(0.5, 1.0), 0.5, min(age - 18, 30)), 1)\n",
        "    bank_years = round(_clip(_sample_tenure() - np.random.uniform(-1.5, 2.5), 0.5, max(0.5, age - 16)), 1)\n",
        "\n",
        "    # Business revenue\n",
        "    if employment in [\"Business Owner\", \"Self Employed\"]:\n",
        "        business_revenue = int(income * np.random.uniform(1.1, 2.5))\n",
        "    else:\n",
        "        business_revenue = 0\n",
        "\n",
        "    # Digital behavior based on age and education\n",
        "    if age < 35 and education in [\"Graduate\", \"Post Graduate\", \"Professional\"]:\n",
        "        mobile_hours = round(np.random.uniform(5.5, 11), 1)\n",
        "        digital_transactions = _sample_digital_transactions() + np.random.randint(15, 35)\n",
        "        social_media = np.random.randint(3, 7)\n",
        "        app_usage_score = np.random.randint(60, 90)\n",
        "        digital_payment_score = np.random.randint(65, 90)\n",
        "    elif age < 50:\n",
        "        mobile_hours = round(np.random.uniform(2.5, 7.5), 1)\n",
        "        digital_transactions = _sample_digital_transactions()\n",
        "        social_media = np.random.randint(2, 5)\n",
        "        app_usage_score = np.random.randint(35, 70)\n",
        "        digital_payment_score = np.random.randint(40, 75)\n",
        "    else:\n",
        "        mobile_hours = round(np.random.uniform(1, 4.5), 1)\n",
        "        digital_transactions = max(8, _sample_digital_transactions() - 15)\n",
        "        social_media = np.random.randint(1, 3)\n",
        "        app_usage_score = np.random.randint(15, 50)\n",
        "        digital_payment_score = np.random.randint(20, 55)\n",
        "\n",
        "    avg_transaction = int((income + expenses) / max(1, digital_transactions) * np.random.uniform(0.4, 1.8))\n",
        "\n",
        "    # Construct test row (NO SCORES OR TARGETS)\n",
        "    row = {\n",
        "        \"applicant_id\": _generate_applicant_id(),\n",
        "        \"application_date\": _generate_application_date(),\n",
        "        \"age\": age,\n",
        "        \"gender\": gender,\n",
        "        \"education_level\": education,\n",
        "        \"employment_type\": employment,\n",
        "        \"marital_status\": marital_status,\n",
        "        \"family_size\": family_size,\n",
        "        \"number_of_dependents\": dependents,\n",
        "        \"location_type\": location_type,\n",
        "        \"monthly_income_inr\": income,\n",
        "        \"spouse_income_inr\": spouse_income,\n",
        "        \"monthly_expenses_inr\": expenses,\n",
        "        \"monthly_savings_inr\": savings,\n",
        "        \"monthly_utility_bills_inr\": utility_bills,\n",
        "        \"property_value_inr\": property_value,\n",
        "        \"vehicle_value_inr\": vehicle_value,\n",
        "        \"total_investments_inr\": investments,\n",
        "        \"outstanding_loan_amount_inr\": outstanding_loan,\n",
        "        \"loan_amount_applied_inr\": loan_application_amount,\n",
        "        \"years_current_employment\": emp_years,\n",
        "        \"banking_relationship_years\": bank_years,\n",
        "        \"monthly_business_revenue_inr\": business_revenue,\n",
        "        \"daily_mobile_hours\": mobile_hours,\n",
        "        \"monthly_digital_transactions\": digital_transactions,\n",
        "        \"avg_transaction_amount_inr\": avg_transaction,\n",
        "        \"social_media_accounts_count\": social_media,\n",
        "        \"mobile_app_usage_intensity_score\": app_usage_score,\n",
        "        \"digital_payment_adoption_score\": digital_payment_score,\n",
        "        \"data_completeness_pct\": np.random.randint(80, 100),\n",
        "        \"consent_status\": \"Full Consent\",\n",
        "        \"explainability_support_flag\": 1,\n",
        "        \"city\": city,\n",
        "    }\n",
        "\n",
        "    return row\n",
        "\n",
        "def generate_test_data(n_rows=3000, seed=222):\n",
        "    \"\"\"Generate test data with diverse profiles\"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Test profile distribution\n",
        "    profiles = {\n",
        "        \"high_earner_low_risk\": 0.20,\n",
        "        \"stable_middle_class\": 0.25,\n",
        "        \"young_professional\": 0.20,\n",
        "        \"average_earner\": 0.20,\n",
        "        \"financial_stress\": 0.10,\n",
        "        \"outlier_case\": 0.05\n",
        "    }\n",
        "\n",
        "    counts = {k: int(v * n_rows) for k, v in profiles.items()}\n",
        "    diff = n_rows - sum(counts.values())\n",
        "    if diff != 0:\n",
        "        counts[\"average_earner\"] += diff\n",
        "\n",
        "    rows = []\n",
        "    for profile_type, count in counts.items():\n",
        "        for _ in range(count):\n",
        "            rows.append(_generate_test_profile(profile_type))\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df[TEST_COLUMNS]\n",
        "\n",
        "    out_csv = os.path.join(OUT_DIR, \"test_data_aligned.csv\")\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "    print(f\"[TEST] ✅ Enhanced test set: {out_csv} shape={df.shape}\")\n",
        "    print(f\"[TEST] Profile distribution: {dict(zip(profiles.keys(), [counts[k] for k in profiles.keys()]))}\")\n",
        "    print(f\"[TEST] Age range: {df['age'].min()} - {df['age'].max()}\")\n",
        "    print(f\"[TEST] Income range: ₹{df['monthly_income_inr'].min():,.0f} - ₹{df['monthly_income_inr'].max():,.0f}\")\n",
        "    print(f\"[TEST] Application amount range: ₹{df['loan_amount_applied_inr'].min():,.0f} - ₹{df['loan_amount_applied_inr'].max():,.0f}\")\n",
        "\n",
        "    # Print dataset integration summary\n",
        "    print(f\"\\n[INFO] Test Dataset Integration Summary:\")\n",
        "    print(f\"  - Loan dataset: {'✅ Loaded' if loan_df is not None else '❌ Not found'}\")\n",
        "    print(f\"  - Telco dataset: {'✅ Loaded' if telco_df is not None else '❌ Not found'}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_test_data(n_rows=50, seed=222)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ughGy4QcnwKD",
        "outputId": "4657bb0b-9ebe-45f6-a5f9-abd86522f9ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded loan dataset for test: (255347, 18)\n",
            "[INFO] Loaded telco dataset for test: (7043, 21)\n",
            "[TEST] ✅ Enhanced test set: credit_risk_output/test_data_aligned.csv shape=(50, 33)\n",
            "[TEST] Profile distribution: {'high_earner_low_risk': 10, 'stable_middle_class': 12, 'young_professional': 10, 'average_earner': 11, 'financial_stress': 5, 'outlier_case': 2}\n",
            "[TEST] Age range: 22 - 55\n",
            "[TEST] Income range: ₹22,000 - ₹188,665\n",
            "[TEST] Application amount range: ₹56,287 - ₹2,000,000\n",
            "\n",
            "[INFO] Test Dataset Integration Summary:\n",
            "  - Loan dataset: ✅ Loaded\n",
            "  - Telco dataset: ✅ Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# XGBoost-only model pipeline: trains, evaluates, saves one PKL, writes CSV+JSON, and generates PNGs\n",
        "# ALIGNED with enhanced training and test data generators - WITH SCORE CALCULATION AND LOAN APPLICATION AMOUNT\n",
        "\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "OUT_DIR = \"credit_risk_output\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Core model features (UPDATED to include loan application amount)\n",
        "MODEL_FEATURES = [\n",
        "    \"age\", \"monthly_income_inr\", \"monthly_expenses_inr\", \"monthly_savings_inr\",\n",
        "    \"outstanding_loan_amount_inr\", \"loan_amount_applied_inr\", \"years_current_employment\",\n",
        "    \"banking_relationship_years\", \"timeliness_score\", \"repayment_ability_score\",\n",
        "    \"financial_health_score\", \"payment_reliability_score\", \"stability_index\"\n",
        "]\n",
        "\n",
        "# Targets (aligned with data generators)\n",
        "TARGET_REG = \"probability_of_default\"\n",
        "TARGET_CLS = \"risk_category\"\n",
        "RISK_LABELS = [\"Low Risk\", \"Medium Risk\", \"High Risk\", \"Very High Risk\"]\n",
        "\n",
        "def convert_np_types(obj):\n",
        "    \"\"\"Convert numpy types to native Python types for JSON serialization\"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convert_np_types(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_np_types(i) for i in obj]\n",
        "    elif isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def _risk_to_num(labels):\n",
        "    \"\"\"Convert risk category labels to numeric (aligned with generators)\"\"\"\n",
        "    mapping = {r: i for i, r in enumerate(RISK_LABELS)}\n",
        "    return np.array([mapping[x] for x in labels], dtype=int)\n",
        "\n",
        "def _risk_category_from_p(p):\n",
        "    \"\"\"Convert probability to risk category (aligned with generators)\"\"\"\n",
        "    if p <= 0.18: return \"Low Risk\"\n",
        "    elif p <= 0.42: return \"Medium Risk\"\n",
        "    elif p <= 0.68: return \"High Risk\"\n",
        "    else: return \"Very High Risk\"\n",
        "\n",
        "def calculate_data_driven_scores(row):\n",
        "    \"\"\"\n",
        "    Calculate scores based on actual financial data including loan application amount.\n",
        "    (UPDATED FROM TRAINING GENERATOR TO ENSURE CONSISTENCY)\n",
        "    \"\"\"\n",
        "    # Extract key financial metrics\n",
        "    income = max(1.0, float(row[\"monthly_income_inr\"]))\n",
        "    expenses = float(row[\"monthly_expenses_inr\"])\n",
        "    savings = float(row[\"monthly_savings_inr\"])\n",
        "    loan_amount = float(row[\"outstanding_loan_amount_inr\"])\n",
        "    application_amount = float(row.get(\"loan_amount_applied_inr\", loan_amount))  # NEW\n",
        "    age = int(row[\"age\"])\n",
        "    emp_years = float(row[\"years_current_employment\"])\n",
        "    bank_years = float(row[\"banking_relationship_years\"])\n",
        "    property_value = float(row.get(\"property_value_inr\", 0))\n",
        "    investments = float(row.get(\"total_investments_inr\", 0))\n",
        "\n",
        "    # Calculate ratios including new application-based metrics\n",
        "    dti_ratio = loan_amount / (12.0 * income) if income > 0 else 0\n",
        "    application_to_income_ratio = application_amount / (12.0 * income) if income > 0 else 0\n",
        "    loan_utilization_ratio = loan_amount / max(1.0, application_amount)\n",
        "    expense_ratio = expenses / income if income > 0 else 1\n",
        "    savings_ratio = savings / income if income > 0 else 0\n",
        "\n",
        "    def _clip_local(value, min_val, max_val):\n",
        "        return max(min_val, min(max_val, value))\n",
        "\n",
        "    # 1. TIMELINESS SCORE (5-95) - Enhanced with application amount consideration\n",
        "    timeliness_base = (\n",
        "        min(emp_years * 8, 40) +\n",
        "        min(bank_years * 6, 30) +\n",
        "        min((age - 18) * 0.8, 20) +\n",
        "        5\n",
        "    )\n",
        "    # Enhanced penalties including application behavior\n",
        "    timeliness_penalty = (dti_ratio * 15 +\n",
        "                         max(0, expense_ratio - 0.7) * 20 +\n",
        "                         max(0, application_to_income_ratio - 1.5) * 10)\n",
        "    timeliness_score = _clip_local(int(timeliness_base - timeliness_penalty + np.random.randint(-8, 9)), 5, 95)\n",
        "\n",
        "    # 2. REPAYMENT ABILITY SCORE (5-90) - Enhanced with application amount factors\n",
        "    repayment_base = (\n",
        "        min(np.log(income/25000) * 15, 30) +\n",
        "        max(0, savings_ratio * 40) +\n",
        "        min(emp_years * 2, 20)\n",
        "    )\n",
        "    repayment_penalty = (dti_ratio * 25 +\n",
        "                        max(0, expense_ratio - 0.8) * 15 +\n",
        "                        max(0, application_to_income_ratio - 2.0) * 12 +\n",
        "                        max(0, loan_utilization_ratio - 0.9) * 8)\n",
        "    repayment_score = _clip_local(int(repayment_base - repayment_penalty + np.random.randint(-6, 7)), 5, 90)\n",
        "\n",
        "    # 3. FINANCIAL HEALTH SCORE (10-95) - Enhanced with application amount\n",
        "    asset_ratio = (property_value + investments) / max(income * 12, 1)\n",
        "    financial_base = (\n",
        "        min(np.log(income/20000) * 12, 25) +\n",
        "        min(asset_ratio * 20, 30) +\n",
        "        max(0, savings_ratio * 25) +\n",
        "        min(bank_years * 1.5, 15)\n",
        "    )\n",
        "    financial_penalty = (dti_ratio * 20 +\n",
        "                        max(0, expense_ratio - 0.75) * 18 +\n",
        "                        max(0, application_to_income_ratio - 1.8) * 10)\n",
        "    financial_score = _clip_local(int(financial_base - financial_penalty + np.random.randint(-10, 11)), 10, 95)\n",
        "\n",
        "    # 4. PAYMENT RELIABILITY SCORE (10-95) - Enhanced with loan behavior\n",
        "    reliability_base = (\n",
        "        min(emp_years * 4, 35) +\n",
        "        max(0, (1 - expense_ratio) * 30) +\n",
        "        min(income/5000, 20) +\n",
        "        10\n",
        "    )\n",
        "    reliability_penalty = (dti_ratio * 30 +\n",
        "                          max(0, expense_ratio - 0.85) * 25 +\n",
        "                          abs(loan_utilization_ratio - 0.7) * 8)\n",
        "    reliability_score = _clip_local(int(reliability_base - reliability_penalty + np.random.randint(-7, 8)), 10, 95)\n",
        "\n",
        "    # 5. STABILITY INDEX (5-90) - Include application amount pattern\n",
        "    stability_base = (\n",
        "        min(emp_years * 3, 25) +\n",
        "        min(bank_years * 2, 15) +\n",
        "        min((age - 20) * 0.6, 20) +\n",
        "        min(asset_ratio * 15, 20) +\n",
        "        10\n",
        "    )\n",
        "    stability_penalty = (dti_ratio * 18 +\n",
        "                        max(0, expense_ratio - 0.8) * 12 +\n",
        "                        max(0, application_to_income_ratio - 2.5) * 8)\n",
        "    stability_score = _clip_local(int(stability_base - stability_penalty + np.random.randint(-12, 13)), 5, 90)\n",
        "\n",
        "    return {\n",
        "        \"timeliness_score\": timeliness_score,\n",
        "        \"repayment_ability_score\": repayment_score,\n",
        "        \"financial_health_score\": financial_score,\n",
        "        \"payment_reliability_score\": reliability_score,\n",
        "        \"stability_index\": stability_score\n",
        "    }\n",
        "\n",
        "def _ensure_scores_present(data, data_type=\"data\"):\n",
        "    \"\"\"\n",
        "    Ensure all required score columns are present in the dataset.\n",
        "    Calculate them if missing using the same logic as training generator.\n",
        "    \"\"\"\n",
        "    score_columns = [\n",
        "        \"timeliness_score\", \"repayment_ability_score\", \"financial_health_score\",\n",
        "        \"payment_reliability_score\", \"stability_index\"\n",
        "    ]\n",
        "\n",
        "    missing_scores = [col for col in score_columns if col not in data.columns]\n",
        "\n",
        "    if missing_scores:\n",
        "        print(f\"[SCORES] Missing score columns in {data_type}: {missing_scores}\")\n",
        "        print(f\"[SCORES] Calculating scores from financial data...\")\n",
        "\n",
        "        # Calculate scores for each row\n",
        "        calculated_scores = []\n",
        "        for idx, row in data.iterrows():\n",
        "            scores = calculate_data_driven_scores(row)\n",
        "            calculated_scores.append(scores)\n",
        "\n",
        "        # Convert to DataFrame and add missing columns\n",
        "        scores_df = pd.DataFrame(calculated_scores)\n",
        "        for col in missing_scores:\n",
        "            if col in scores_df.columns:\n",
        "                data[col] = scores_df[col]\n",
        "\n",
        "        print(f\"[SCORES] ✅ Calculated and added {len(missing_scores)} score columns\")\n",
        "    else:\n",
        "        print(f\"[SCORES] ✅ All score columns present in {data_type}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def _validate_loan_data(data, data_type=\"data\"):\n",
        "    \"\"\"\n",
        "    NEW: Validate loan application amount data\n",
        "    \"\"\"\n",
        "    print(f\"[VALIDATION] Validating loan data in {data_type}...\")\n",
        "\n",
        "    # Check for required columns\n",
        "    required_cols = [\"loan_amount_applied_inr\", \"outstanding_loan_amount_inr\", \"monthly_income_inr\"]\n",
        "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing required columns in {data_type}: {missing_cols}\")\n",
        "\n",
        "    # Check for negative values\n",
        "    if (data[\"loan_amount_applied_inr\"] < 0).any():\n",
        "        raise ValueError(f\"Negative loan application amounts found in {data_type}\")\n",
        "\n",
        "    # Logical validation: outstanding should generally not exceed applied (with tolerance for interest)\n",
        "    over_applied = data[data[\"outstanding_loan_amount_inr\"] > data[\"loan_amount_applied_inr\"] * 1.15]\n",
        "    if len(over_applied) > 0:\n",
        "        print(f\"[WARNING] {len(over_applied)} records in {data_type} have outstanding > 115% of applied amount\")\n",
        "\n",
        "    # Check for extremely high application amounts relative to income\n",
        "    high_ratio = data[data[\"loan_amount_applied_inr\"] > data[\"monthly_income_inr\"] * 12 * 10]\n",
        "    if len(high_ratio) > 0:\n",
        "        print(f\"[WARNING] {len(high_ratio)} records in {data_type} have application > 10x annual income\")\n",
        "\n",
        "    print(f\"[VALIDATION] ✅ Loan data validation completed for {data_type}\")\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(f\"[SUMMARY] Application amounts in {data_type}:\")\n",
        "    print(f\"  - Min: ₹{data['loan_amount_applied_inr'].min():,.0f}\")\n",
        "    print(f\"  - Max: ₹{data['loan_amount_applied_inr'].max():,.0f}\")\n",
        "    print(f\"  - Mean: ₹{data['loan_amount_applied_inr'].mean():,.0f}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def _add_derived_features(data):\n",
        "    \"\"\"\n",
        "    NEW: Add derived features from loan application amount\n",
        "    \"\"\"\n",
        "    print(\"[FEATURES] Adding derived features from loan application data...\")\n",
        "\n",
        "    # Application to income ratio\n",
        "    data[\"application_to_income_ratio\"] = data[\"loan_amount_applied_inr\"] / (data[\"monthly_income_inr\"] * 12)\n",
        "\n",
        "    # Loan utilization ratio (how much of applied amount is outstanding)\n",
        "    data[\"loan_utilization_ratio\"] = data[\"outstanding_loan_amount_inr\"] / data[\"loan_amount_applied_inr\"]\n",
        "\n",
        "    # Application amount category\n",
        "    data[\"application_amount_category\"] = pd.cut(\n",
        "        data[\"loan_amount_applied_inr\"],\n",
        "        bins=[0, 100000, 500000, 1000000, float('inf')],\n",
        "        labels=['Small', 'Medium', 'Large', 'Very Large']\n",
        "    )\n",
        "\n",
        "    print(\"[FEATURES] ✅ Added derived features:\")\n",
        "    print(\"  - application_to_income_ratio\")\n",
        "    print(\"  - loan_utilization_ratio\")\n",
        "    print(\"  - application_amount_category\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def _load_data():\n",
        "    \"\"\"Load training and test data with proper validation and score calculation\"\"\"\n",
        "    train = pd.read_csv(os.path.join(OUT_DIR, \"training_data_aligned.csv\"))\n",
        "    test = pd.read_csv(os.path.join(OUT_DIR, \"test_data_aligned.csv\"))\n",
        "\n",
        "    print(f\"[DATA] Loaded training  {train.shape}\")\n",
        "    print(f\"[DATA] Loaded test  {test.shape}\")\n",
        "\n",
        "    # NEW: Validate loan application data\n",
        "    train = _validate_loan_data(train, \"training\")\n",
        "    test = _validate_loan_data(test, \"test\")\n",
        "\n",
        "    # Ensure scores are present in both datasets\n",
        "    train = _ensure_scores_present(train, \"training\")\n",
        "    test = _ensure_scores_present(test, \"test\")\n",
        "\n",
        "    # NEW: Add derived features (optional - can be commented out if not needed)\n",
        "    # train = _add_derived_features(train)\n",
        "    # test = _add_derived_features(test)\n",
        "\n",
        "    # Validate training data has all required columns\n",
        "    missing_train = [c for c in MODEL_FEATURES + [TARGET_REG, TARGET_CLS] if c not in train.columns]\n",
        "    assert not missing_train, f\"Training missing columns: {missing_train}\"\n",
        "\n",
        "    # Validate test data has model features (targets may or may not be present)\n",
        "    missing_test = [c for c in MODEL_FEATURES if c not in test.columns]\n",
        "    assert not missing_test, f\"Test missing columns: {missing_test}\"\n",
        "\n",
        "    print(f\"[DATA] ✅ Training data shape: {train.shape}\")\n",
        "    print(f\"[DATA] ✅ Test data shape: {test.shape}\")\n",
        "    print(f\"[DATA] Test has targets: {TARGET_REG in test.columns and TARGET_CLS in test.columns}\")\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def _fit_xgboost_models(X_train, y_reg_train, y_cls_train_num, eval_fraction=0.25, seed=42):\n",
        "    \"\"\"Enhanced XGBoost model fitting with improved hyperparameters (aligned with data complexity)\"\"\"\n",
        "    # Stratified split to maintain class balance\n",
        "    stratify_opt = y_cls_train_num if len(np.unique(y_cls_train_num)) > 1 else None\n",
        "    X_tr, X_val, yreg_tr, yreg_val, ycls_tr, ycls_val = train_test_split(\n",
        "        X_train, y_reg_train, y_cls_train_num, test_size=eval_fraction,\n",
        "        random_state=seed, stratify=stratify_opt\n",
        "    )\n",
        "\n",
        "    # Enhanced XGBoost Regressor (tuned for financial data with loan application features)\n",
        "    xgb_reg = XGBRegressor(\n",
        "        n_estimators=900,            # More trees for better learning with additional features\n",
        "        learning_rate=0.05,          # Slightly lower learning rate for stability\n",
        "        max_depth=8,                 # Deeper trees for complex financial relationships\n",
        "        subsample=0.85,              # Row sampling for regularization\n",
        "        colsample_bytree=0.8,        # Feature sampling\n",
        "        colsample_bylevel=0.8,       # Additional feature sampling per level\n",
        "        reg_alpha=0.1,               # L1 regularization\n",
        "        reg_lambda=2.0,              # Higher L2 regularization for more features\n",
        "        min_child_weight=4,          # Prevent overfitting on small groups\n",
        "        gamma=0.1,                   # Minimum split loss\n",
        "        random_state=seed,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Enhanced XGBoost Classifier (tuned for risk categories with loan features)\n",
        "    xgb_cls = XGBClassifier(\n",
        "        n_estimators=1000,           # More estimators for classification with additional features\n",
        "        learning_rate=0.05,\n",
        "        max_depth=8,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.8,\n",
        "        colsample_bylevel=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=2.0,\n",
        "        min_child_weight=4,\n",
        "        gamma=0.1,\n",
        "        random_state=seed,\n",
        "        eval_metric=\"mlogloss\",\n",
        "        use_label_encoder=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(\"[MODEL] Training XGBoost models...\")\n",
        "    print(f\"[MODEL] Training features: {X_train.shape[1]} (including loan_amount_applied_inr)\")\n",
        "\n",
        "    # Fit models on training split\n",
        "    xgb_reg.fit(X_tr, yreg_tr)\n",
        "    xgb_cls.fit(X_tr, ycls_tr)\n",
        "\n",
        "    # Validate on hold-out set\n",
        "    y_val_pred_reg = xgb_reg.predict(X_val)\n",
        "    y_val_pred_cls_num = xgb_cls.predict(X_val)\n",
        "    y_val_pred_cls_str = np.array([RISK_LABELS[int(v)] for v in y_val_pred_cls_num])\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    y_val_cls_str = np.array([RISK_LABELS[int(v)] for v in ycls_val])\n",
        "    acc = accuracy_score(y_val_cls_str, y_val_pred_cls_str)\n",
        "    mae = mean_absolute_error(yreg_val, y_val_pred_reg)\n",
        "\n",
        "    # Binary classification AUC (High/Very High vs others)\n",
        "    y_bin = (ycls_val >= 2).astype(int)\n",
        "    auc_bin = roc_auc_score(y_bin, y_val_pred_reg) if len(np.unique(y_bin)) > 1 else float(\"nan\")\n",
        "\n",
        "    metrics = {\"accuracy\": acc, \"mae\": mae, \"auc_bin\": auc_bin}\n",
        "    print(f\"[VALIDATION] Accuracy: {acc:.4f}, MAE: {mae:.4f}, AUC: {auc_bin:.4f}\")\n",
        "\n",
        "    # Refit on full training data for final models\n",
        "    print(\"[MODEL] Refitting on full training data...\")\n",
        "    xgb_reg.fit(X_train, y_reg_train)\n",
        "    xgb_cls.fit(X_train, y_cls_train_num)\n",
        "\n",
        "    return xgb_reg, xgb_cls, (X_val, y_val_cls_str, y_val_pred_reg, y_val_pred_cls_str, yreg_val, metrics)\n",
        "\n",
        "def _generate_test_predictions(xgb_reg, xgb_cls, test_data):\n",
        "    \"\"\"Generate predictions on test data with risk score calculation (aligned with generators)\"\"\"\n",
        "    X_test = test_data[MODEL_FEATURES].copy()\n",
        "\n",
        "    print(\"[PREDICTION] Generating test predictions...\")\n",
        "    print(f\"[PREDICTION] Using features: {MODEL_FEATURES}\")\n",
        "\n",
        "    # Predict probability of default and risk category\n",
        "    test_pred_reg = xgb_reg.predict(X_test)\n",
        "    test_pred_cls_num = xgb_cls.predict(X_test)\n",
        "    test_pred_cls_str = np.array([RISK_LABELS[int(v)] for v in test_pred_cls_num])\n",
        "\n",
        "    # Create results dataframe with predictions\n",
        "    test_results = test_data.copy()\n",
        "    test_results[TARGET_REG] = test_pred_reg\n",
        "    test_results[TARGET_CLS] = test_pred_cls_str\n",
        "\n",
        "    # Calculate risk score (aligned with generator format)\n",
        "    test_results[\"risk_score\"] = (test_results[TARGET_REG] * 100).round(1)\n",
        "\n",
        "    print(f\"[PREDICTION] ✅ Test predictions completed. Shape: {test_results.shape}\")\n",
        "    print(f\"[PREDICTION] Risk distribution: {pd.Series(test_pred_cls_str).value_counts().to_dict()}\")\n",
        "    print(f\"[PREDICTION] PD range: {test_pred_reg.min():.3f} - {test_pred_reg.max():.3f}\")\n",
        "    print(f\"[PREDICTION] Application amounts in test predictions: ₹{test_results['loan_amount_applied_inr'].min():,.0f} - ₹{test_results['loan_amount_applied_inr'].max():,.0f}\")\n",
        "\n",
        "    return test_results, test_pred_reg, test_pred_cls_str\n",
        "\n",
        "def _save_pngs(xgb_reg, X_val, y_val_cls_str, y_val_pred_reg, y_val_pred_cls_str):\n",
        "    \"\"\"Generate all visualization plots\"\"\"\n",
        "    print(\"[PLOTS] Generating visualizations...\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    labels = RISK_LABELS\n",
        "    cm = confusion_matrix(y_val_cls_str, y_val_pred_cls_str, labels=labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title('Confusion Matrix - XGBoost (with Loan Application Features)')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix_best.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # ROC Curve (High/Very High vs others) using regressor scores\n",
        "    y_true_num = _risk_to_num(y_val_cls_str)\n",
        "    y_bin = (y_true_num >= 2).astype(int)\n",
        "    if len(np.unique(y_bin)) > 1:\n",
        "        fpr, tpr, _ = roc_curve(y_bin, y_val_pred_reg)\n",
        "        auc_val = roc_auc_score(y_bin, y_val_pred_reg)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"XGB Enhanced (AUC={auc_val:.3f})\")\n",
        "        plt.plot([0, 1], [0, 1], lw=2, linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(\"ROC Curve (High/Very High vs others)\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUT_DIR, \"roc_curve_best.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "    # Feature Importance (regressor) - UPDATED to show loan application feature\n",
        "    if hasattr(xgb_reg, \"feature_importances_\"):\n",
        "        importances = np.array(xgb_reg.feature_importances_)\n",
        "        idx = np.argsort(importances)[::-1]\n",
        "        top_n = min(len(MODEL_FEATURES), len(importances))\n",
        "\n",
        "        plt.figure(figsize=(12, 8))  # Larger figure for more features\n",
        "        plt.barh(range(top_n), importances[idx[:top_n]][::-1])\n",
        "        feature_names = [MODEL_FEATURES[i] for i in idx[:top_n]][::-1]\n",
        "\n",
        "        # Highlight loan application feature if it's in top features\n",
        "        colors = ['red' if 'loan_amount_applied' in name else 'steelblue' for name in feature_names]\n",
        "        plt.barh(range(top_n), importances[idx[:top_n]][::-1], color=colors)\n",
        "\n",
        "        plt.yticks(range(top_n), feature_names)\n",
        "        plt.xlabel(\"Relative Importance\")\n",
        "        plt.title(\"Feature Importance - XGBoost Regressor (Enhanced with Loan Application)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUT_DIR, \"feature_importance_best.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "        # Print feature importance for loan application amount\n",
        "        loan_app_idx = MODEL_FEATURES.index(\"loan_amount_applied_inr\")\n",
        "        loan_app_importance = importances[loan_app_idx]\n",
        "        print(f\"[FEATURE IMPORTANCE] loan_amount_applied_inr importance: {loan_app_importance:.4f} (rank: {np.where(idx == loan_app_idx)[0][0] + 1}/{len(MODEL_FEATURES)})\")\n",
        "\n",
        "    # Risk Distribution Visualization\n",
        "    risk_dist = pd.Series(y_val_cls_str).value_counts()\n",
        "    pred_dist = pd.Series(y_val_pred_cls_str).value_counts()\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    x_pos = np.arange(len(RISK_LABELS))\n",
        "    width = 0.35\n",
        "    actual_counts = [risk_dist.get(label, 0) for label in RISK_LABELS]\n",
        "    pred_counts = [pred_dist.get(label, 0) for label in RISK_LABELS]\n",
        "    plt.bar(x_pos - width/2, actual_counts, width, label='Actual', alpha=0.8)\n",
        "    plt.bar(x_pos + width/2, pred_counts, width, label='Predicted', alpha=0.8)\n",
        "    plt.xlabel('Risk Categories')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Risk Distribution: Actual vs Predicted (Enhanced Model)')\n",
        "    plt.xticks(x_pos, RISK_LABELS, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"risk_distribution.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def _update_metric_plots(acc, mae, y_reg_val, y_reg_pred):\n",
        "    \"\"\"Generate performance comparison plots\"\"\"\n",
        "    # Accuracy Comparison with actual bars\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    metrics_names = [\"Accuracy\", \"1 - MAE\"]\n",
        "    plt.bar([0, 1], [acc, max(0.0, 1.0 - mae)], width=0.5, color=[\"#4c72b0\", \"#55a868\"])\n",
        "    for i, v in enumerate([acc, max(0.0, 1.0 - mae)]):\n",
        "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
        "    plt.xticks([0, 1], metrics_names)\n",
        "    plt.title(\"Model Performance Comparison (XGBoost Enhanced)\")\n",
        "    plt.xlabel(\"Metric\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"accuracy_comparison.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # Prediction Errors with real residuals\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    errors = y_reg_val - y_reg_pred\n",
        "    plt.scatter(y_reg_pred, errors, alpha=0.6)\n",
        "    plt.axhline(y=0, color='r', linestyle='--')\n",
        "    plt.xlabel('Predicted Probability of Default')\n",
        "    plt.ylabel('Prediction Error')\n",
        "    plt.title('Prediction Errors - XGBoost Regressor (Enhanced)')\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"prediction_errors.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main pipeline execution (aligned with data generator workflow)\"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"🚀 XGBoost Credit Risk Pipeline - Enhanced with Loan Application Amount\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n[STEP 1] Loading and validating data...\")\n",
        "    train, test = _load_data()\n",
        "\n",
        "    # Prepare training data\n",
        "    X_train = train[MODEL_FEATURES].copy()\n",
        "    y_reg_train = train[TARGET_REG].astype(float).copy()\n",
        "    y_cls_train_str = train[TARGET_CLS].astype(str).copy()\n",
        "    y_cls_train_num = _risk_to_num(y_cls_train_str)\n",
        "\n",
        "    print(f\"[TRAIN] Training features shape: {X_train.shape}\")\n",
        "    print(f\"[TRAIN] Model features include loan_amount_applied_inr: {'loan_amount_applied_inr' in MODEL_FEATURES}\")\n",
        "    print(f\"[TRAIN] Risk distribution: {pd.Series(y_cls_train_str).value_counts().to_dict()}\")\n",
        "\n",
        "    print(\"\\n[STEP 2] Training enhanced XGBoost models...\")\n",
        "    xgb_reg, xgb_cls, validation = _fit_xgboost_models(X_train, y_reg_train, y_cls_train_num)\n",
        "    X_val, y_val_cls_str, y_val_pred_reg, y_val_pred_cls_str, y_reg_val, val_metrics = validation\n",
        "\n",
        "    print(\"\\n[STEP 3] Generating enhanced visualizations...\")\n",
        "    _save_pngs(xgb_reg, X_val, y_val_cls_str, y_val_pred_reg, y_val_pred_cls_str)\n",
        "    _update_metric_plots(val_metrics[\"accuracy\"], val_metrics[\"mae\"], y_reg_val, y_val_pred_reg)\n",
        "\n",
        "    print(\"\\n[STEP 4] Predicting on test data...\")\n",
        "    test_results, test_pred_reg, test_pred_cls_str = _generate_test_predictions(xgb_reg, xgb_cls, test)\n",
        "\n",
        "    print(\"\\n[STEP 5] Saving results...\")\n",
        "\n",
        "    # Save test predictions CSV (aligned with generator format)\n",
        "    test_results.to_csv(os.path.join(OUT_DIR, \"test_predictions.csv\"), index=False)\n",
        "    print(f\"[SAVE] ✅ Test predictions saved: test_predictions.csv\")\n",
        "\n",
        "    # Save complete model pipeline (single PKL file) - UPDATED\n",
        "    full_pipeline = {\n",
        "        \"xgb_regressor\": xgb_reg,\n",
        "        \"xgb_classifier\": xgb_cls,\n",
        "        \"risk_labels\": RISK_LABELS,\n",
        "        \"model_features\": MODEL_FEATURES,  # Now includes loan_amount_applied_inr\n",
        "        \"metadata\": {\n",
        "            \"train_shape\": list(X_train.shape),\n",
        "            \"test_shape\": list(test[MODEL_FEATURES].shape),\n",
        "            \"risk_mapping\": {label: i for i, label in enumerate(RISK_LABELS)},\n",
        "            \"pd_thresholds\": {\"low\": 0.18, \"medium\": 0.42, \"high\": 0.68},\n",
        "            \"enhanced_features\": [\"loan_amount_applied_inr\"],  # NEW\n",
        "            \"model_version\": \"enhanced_with_loan_application\"  # NEW\n",
        "        }\n",
        "    }\n",
        "    joblib.dump(full_pipeline, os.path.join(OUT_DIR, \"xgb_credit_risk_pipeline.pkl\"))\n",
        "    print(f\"[SAVE] ✅ Enhanced model pipeline saved: xgb_credit_risk_pipeline.pkl\")\n",
        "\n",
        "    # Generate comprehensive JSON output (aligned with generator analysis) - UPDATED\n",
        "    cm = confusion_matrix(y_val_cls_str, y_val_pred_cls_str, labels=RISK_LABELS).tolist()\n",
        "    class_report = classification_report(y_val_cls_str, y_val_pred_cls_str, output_dict=True)\n",
        "\n",
        "    # Feature importances from regressor\n",
        "    feat_imps = []\n",
        "    if hasattr(full_pipeline[\"xgb_regressor\"], \"feature_importances_\"):\n",
        "        for f, w in zip(MODEL_FEATURES, full_pipeline[\"xgb_regressor\"].feature_importances_):\n",
        "            feat_imps.append({\n",
        "                \"feature\": f,\n",
        "                \"importance\": float(w),\n",
        "                \"is_loan_application_feature\": \"loan_amount_applied\" in f  # NEW\n",
        "            })\n",
        "\n",
        "    output_json = {\n",
        "        \"data\": test_results.to_dict(orient=\"records\"),\n",
        "        \"analysis\": {\n",
        "            \"metrics\": {\n",
        "                \"accuracy\": float(val_metrics[\"accuracy\"]),\n",
        "                \"mae\": float(val_metrics[\"mae\"]),\n",
        "                \"auc_bin\": float(val_metrics[\"auc_bin\"]) if np.isfinite(val_metrics[\"auc_bin\"]) else None\n",
        "            },\n",
        "            \"confusion_matrix\": {\n",
        "                \"labels\": RISK_LABELS,\n",
        "                \"matrix\": cm\n",
        "            },\n",
        "            \"classification_report\": class_report,\n",
        "            \"class_distribution_validation\": dict(pd.Series(y_val_cls_str).value_counts()),\n",
        "            \"class_distribution_test_predicted\": dict(pd.Series(test_pred_cls_str).value_counts()),\n",
        "            \"feature_importance_regressor\": feat_imps,\n",
        "            \"shapes\": {\n",
        "                \"train\": list(X_train.shape),\n",
        "                \"validation\": list(X_val.shape),\n",
        "                \"test\": list(test[MODEL_FEATURES].shape)\n",
        "            },\n",
        "            \"model_info\": {\n",
        "                \"algorithm\": \"XGBoost Enhanced\",\n",
        "                \"version\": \"enhanced_with_loan_application\",  # NEW\n",
        "                \"features_count\": len(MODEL_FEATURES),  # NEW\n",
        "                \"has_loan_application_feature\": True,  # NEW\n",
        "                \"regressor_params\": xgb_reg.get_params(),\n",
        "                \"classifier_params\": xgb_cls.get_params()\n",
        "            },\n",
        "            \"loan_application_analysis\": {  # NEW SECTION\n",
        "                \"application_amount_range\": {\n",
        "                    \"min\": float(test_results[\"loan_amount_applied_inr\"].min()),\n",
        "                    \"max\": float(test_results[\"loan_amount_applied_inr\"].max()),\n",
        "                    \"mean\": float(test_results[\"loan_amount_applied_inr\"].mean())\n",
        "                },\n",
        "                \"loan_utilization_stats\": {\n",
        "                    \"mean\": float((test_results[\"outstanding_loan_amount_inr\"] / test_results[\"loan_amount_applied_inr\"]).mean()),\n",
        "                    \"median\": float((test_results[\"outstanding_loan_amount_inr\"] / test_results[\"loan_amount_applied_inr\"]).median())\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Convert numpy types before JSON serialization\n",
        "    json_safe_output = convert_np_types(output_json)\n",
        "    with open(os.path.join(OUT_DIR, \"model_output.json\"), \"w\") as f:\n",
        "        json.dump(json_safe_output, f, indent=2)\n",
        "    print(f\"[SAVE] ✅ Enhanced JSON analysis saved: model_output.json\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"✅ Enhanced XGBoost Credit Risk Pipeline Completed!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"📊 PERFORMANCE METRICS:\")\n",
        "    print(f\"   ├── Regressor MAE: {val_metrics['mae']:.4f}\")\n",
        "    print(f\"   ├── Classifier Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   └── Binary AUC (High Risk): {val_metrics['auc_bin']:.4f}\")\n",
        "    print(f\"\\n🆕 ENHANCEMENT FEATURES:\")\n",
        "    print(f\"   ├── Total Features: {len(MODEL_FEATURES)} (including loan_amount_applied_inr)\")\n",
        "    print(f\"   ├── Loan Application Amount: ✅ Included\")\n",
        "    print(f\"   ├── Enhanced Score Calculations: ✅ Updated\")\n",
        "    print(f\"   └── Validation & Derived Features: ✅ Added\")\n",
        "    print(f\"\\n📁 OUTPUT FILES:\")\n",
        "    print(f\"   ├── training_data_aligned.csv\")\n",
        "    print(f\"   ├── test_data_aligned.csv\")\n",
        "    print(f\"   ├── test_predictions.csv (with loan application data)\")\n",
        "    print(f\"   ├── xgb_credit_risk_pipeline.pkl (enhanced model)\")\n",
        "    print(f\"   ├── model_output.json (comprehensive analysis with loan features)\")\n",
        "    print(f\"   └── 6 PNG visualizations (enhanced with loan application insights)\")\n",
        "    print(\"\\n🎯 Model now fully utilizes loan application amount for improved predictions!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPlPp5enzo8",
        "outputId": "3c6cc434-df17-4c29-bf99-108c46f18e23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "🚀 XGBoost Credit Risk Pipeline - Enhanced with Loan Application Amount\n",
            "======================================================================\n",
            "\n",
            "[STEP 1] Loading and validating data...\n",
            "[DATA] Loaded training  (12000, 43)\n",
            "[DATA] Loaded test  (50, 33)\n",
            "[VALIDATION] Validating loan data in training...\n",
            "[VALIDATION] ✅ Loan data validation completed for training\n",
            "[SUMMARY] Application amounts in training:\n",
            "  - Min: ₹25,000\n",
            "  - Max: ₹8,000,000\n",
            "  - Mean: ₹1,595,464\n",
            "[VALIDATION] Validating loan data in test...\n",
            "[VALIDATION] ✅ Loan data validation completed for test\n",
            "[SUMMARY] Application amounts in test:\n",
            "  - Min: ₹56,287\n",
            "  - Max: ₹2,000,000\n",
            "  - Mean: ₹924,646\n",
            "[SCORES] ✅ All score columns present in training\n",
            "[SCORES] Missing score columns in test: ['timeliness_score', 'repayment_ability_score', 'financial_health_score', 'payment_reliability_score', 'stability_index']\n",
            "[SCORES] Calculating scores from financial data...\n",
            "[SCORES] ✅ Calculated and added 5 score columns\n",
            "[DATA] ✅ Training data shape: (12000, 43)\n",
            "[DATA] ✅ Test data shape: (50, 38)\n",
            "[DATA] Test has targets: False\n",
            "[TRAIN] Training features shape: (12000, 13)\n",
            "[TRAIN] Model features include loan_amount_applied_inr: True\n",
            "[TRAIN] Risk distribution: {'Medium Risk': 5297, 'High Risk': 3209, 'Low Risk': 2103, 'Very High Risk': 1391}\n",
            "\n",
            "[STEP 2] Training enhanced XGBoost models...\n",
            "[MODEL] Training XGBoost models...\n",
            "[MODEL] Training features: 13 (including loan_amount_applied_inr)\n",
            "[VALIDATION] Accuracy: 0.7083, MAE: 0.0673, AUC: 0.9632\n",
            "[MODEL] Refitting on full training data...\n",
            "\n",
            "[STEP 3] Generating enhanced visualizations...\n",
            "[PLOTS] Generating visualizations...\n",
            "[FEATURE IMPORTANCE] loan_amount_applied_inr importance: 0.0824 (rank: 5/13)\n",
            "\n",
            "[STEP 4] Predicting on test data...\n",
            "[PREDICTION] Generating test predictions...\n",
            "[PREDICTION] Using features: ['age', 'monthly_income_inr', 'monthly_expenses_inr', 'monthly_savings_inr', 'outstanding_loan_amount_inr', 'loan_amount_applied_inr', 'years_current_employment', 'banking_relationship_years', 'timeliness_score', 'repayment_ability_score', 'financial_health_score', 'payment_reliability_score', 'stability_index']\n",
            "[PREDICTION] ✅ Test predictions completed. Shape: (50, 41)\n",
            "[PREDICTION] Risk distribution: {'Medium Risk': 25, 'Low Risk': 10, 'High Risk': 9, 'Very High Risk': 6}\n",
            "[PREDICTION] PD range: 0.112 - 0.866\n",
            "[PREDICTION] Application amounts in test predictions: ₹56,287 - ₹2,000,000\n",
            "\n",
            "[STEP 5] Saving results...\n",
            "[SAVE] ✅ Test predictions saved: test_predictions.csv\n",
            "[SAVE] ✅ Enhanced model pipeline saved: xgb_credit_risk_pipeline.pkl\n",
            "[SAVE] ✅ Enhanced JSON analysis saved: model_output.json\n",
            "\n",
            "======================================================================\n",
            "✅ Enhanced XGBoost Credit Risk Pipeline Completed!\n",
            "======================================================================\n",
            "📊 PERFORMANCE METRICS:\n",
            "   ├── Regressor MAE: 0.0673\n",
            "   ├── Classifier Accuracy: 0.7083\n",
            "   └── Binary AUC (High Risk): 0.9632\n",
            "\n",
            "🆕 ENHANCEMENT FEATURES:\n",
            "   ├── Total Features: 13 (including loan_amount_applied_inr)\n",
            "   ├── Loan Application Amount: ✅ Included\n",
            "   ├── Enhanced Score Calculations: ✅ Updated\n",
            "   └── Validation & Derived Features: ✅ Added\n",
            "\n",
            "📁 OUTPUT FILES:\n",
            "   ├── training_data_aligned.csv\n",
            "   ├── test_data_aligned.csv\n",
            "   ├── test_predictions.csv (with loan application data)\n",
            "   ├── xgb_credit_risk_pipeline.pkl (enhanced model)\n",
            "   ├── model_output.json (comprehensive analysis with loan features)\n",
            "   └── 6 PNG visualizations (enhanced with loan application insights)\n",
            "\n",
            "🎯 Model now fully utilizes loan application amount for improved predictions!\n"
          ]
        }
      ]
    }
  ]
}